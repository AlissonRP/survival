\subsection{Competing risks}
\newcommand{\Twid}{\mbox{\(\tt\sim\)}}
The competing risks routine is very general, allowing subjects
to enter or exit states multiple times.
For this reason I prefer the label \emph{current prevalence} estimate, 
since it estimates what fraction of the subjects are in any
given state across time.  
However the word ``prevalence'' is likely to generate confusion whenever
death is one of the states, due to its historic use as the fraction of
living subjects who have a particular condition.
We will use the phrase \emph{probability in state} or simply $P$
from this point forward.

The easiest way to understand the estimate is to consider first the
case of no censoring.  
In that setting the estimate of $F_k(t) = 1-S_k(t)$ for all states
is obtained from a simple table of the current state at time $t$
of the subjects, divided by $n$, the original
sample size.
When there is censoring the conceptually simple way to extend this
is via the redistribute-to-the-right algorithm, which allocates the
case weight for a censored subject evenly to all the others in the
same state at the time of censoring.  

The literature refers to these as ``cumulative incidence'' curves,
which is confusing since prevalence is not the integral of incidence,
but the routine name survfitCI endures.
The cannonical call is
\begin{verbatim}
  fit <- survfit(Surv(time, status, type='mstate') ~ sex, data=mine)
\end{verbatim}
 Optionally, there can be an id statement
or cluster term to indicate a data set with multiple transitions per subject.
A multi-state survival fit has a status variable with multiple levels,
the first of which by default is censoring, and others indicating
the type of transition that occured.
The result will be a matrix of survival curves, one for each event type.
In no initial state is specified then subjects are assumed
to start in a "null" state, which gets listed last and by default will
not be printed or plotted.  (But it is present, with a name of `');
  
The first part of the code is standard, parsing out options and
checking the data.
<<survfitCI>>= 
<<survfitCI-compute>>
survfitCI <- function(X, Y, weights, id, istate, 
                      type=c('kaplan-meier', 'fleming-harrington', 'fh2'),
                      se.fit=TRUE,
                      conf.int= .95,
                      conf.type=c('log',  'log-log',  'plain', 'none'),
                      conf.lower=c('usual', 'peto', 'modified'),
                      influence = FALSE){

    method <- match.arg(type)
#    error <- match.arg(error)
#    if (error != "inf")
#        warning("Only the infinetesimal jackknife error is supported for CI curves")
    conf.type <- match.arg(conf.type)
    conf.lower<- match.arg(conf.lower)
    if (is.logical(conf.int)) {
        # A common error is for users to use "conf.int = FALSE"
        #  it's illegal per documentation, but be kind
        if (!conf.int) conf.type <- "none"
        conf.int <- .95
    }

    type <- attr(Y, "type")
    # This line should be unreachable, unless they call "surfitCI"
    if (type !='mright' && type!='mcounting')
         stop(paste("multi-state computation doesn't support \"", type,
                          "\" survival data", sep=''))

    n <- nrow(Y)
    status <- Y[,ncol(Y)]
    ncurve <- length(levels(X))
    
    state.names <- attr(Y, "states")
    nstate <- length(state.names) 
    has.istate <- !missing(istate)
    if (missing(istate) || is.null(istate)) {
        istate <- rep(nstate+ 1L, n)
        state.names <- c(state.names, "")
        }
    else {
        if (is.factor(istate) || is.character(istate)) {
            # Match levels with the survival variable
            temp <- as.factor(istate)
            # append any starting states not found in Y, but remember that
            #  if istate was a factor then not all its levels might appear
            appear <- (levels(temp))[unique(as.numeric(temp))]
            state.names <- unique(c(attr(Y, "states"), appear))
            istate <- as.numeric(factor(as.character(temp), levels=state.names))
        }
        else {
            if (!is.numeric(istate) || any(istate != floor(istate)) || 
                any(istate < 1))
                stop("istate should be a vector of integers or a factor")
            if (max(istate) > nstate) 
                state.names <- c(state.names, (1+nstate):max(istate))
        }
    }  
    if (length(id) ==0) id <- 1:n
    # these next two lines should be impossible, since istate came from 
    #   the data frame
    if (length(istate) ==1) istate <- rep(istate,n)
    if (length(istate) !=n) stop ("wrong length for istate")

    # The states of the status variable are the first columns in the output
    states <- unique(c(1:nstate, istate))
@
 
To make it easier to keep track of things in the computational kernel that does
all the real work, we ensure that any ending states (ones you can reach)
are 1, 2, 3 \ldots.
The status vector will have values of 0 for censored.
<<survfitCI>>=
    curves <- vector("list", ncurve)
    names(curves) <- levels(X)
                            
    if (ncol(Y)==2) {  # 1 transition per subject
        indx <- which(status == istate & status!=0)
        if (length(indx)) {
            warning("an observation transitions to it's starting state, transition ignored")
            status[indx] <- 0
        }
        if (length(id) && any(duplicated(id)))
            stop("Cannot have duplicate id values with (time, status) data")

        # make a table of transitions.  Variable 'from' can range across
        #  all of the states, 'to' can only have nstate categories
        nst <- length(state.names)
        transitions <- table(factor(istate, 1:nst), factor(Y[,2], 1:nstate))
        dimnames(transitions) <-list(from=state.names, to=state.names[1:nstate])
                             
        # dummy entry time that is < any event time
        entry <- rep(0L, nrow(Y))  # due to the use of normalizetime  
        for (i in levels(X)) {
            indx <- which(X==i)
 #           temp  <- docurve1(entry[indx], Y[indx,1], status[indx], 
 #                                   istate[indx], weights[indx], states, 
 #                                   id[indx])
            curves[[i]] <- docurve2(entry[indx], Y[indx,1], status[indx], 
                                    istate[indx], weights[indx], states, 
                                    id[indx], se.fit)
         }
    }
    else {
        <<survfitCI-idcheck>>
        <<survfitCI-startstop>>
    }

    <<survfitCI-finish>>
}
@         
        
In the multi-state case we can calculate the current prevalence
vector $p(t)$ using the product-limit form
\begin{align*}
    p(t) &= p(0)\prod_{s<=t} [I + dA(s)] \\
         &= p(0) \prod_{s<=t} H(s)
\end{align*}
Where $p$ is a row vector and $H$ is the multi-state hazard matrix.  
$H(t)$ is a simple transition matrix.  
Row $j$ of $H$ describes the outcome of everyone who was in state $j$ at
time $t-0$; and is the fraction of them who are in states $1, 2, \ldots$
at time $t+0$.  
Let $Y_{ij}(t)$ be the indicator function which is 1 if subject $i$
is in state $j$ at time $t-0$, then
\begin{equation}
  H_{jk}(t) = \frac{\sum_i w_i Y_{ij}(t) Y_{ik}(t+)}
                  {\sum_i w_i Y_{ij}(t)} \label{H}
\end{equation}
Each row of $H$ sums to 1: everyone has to go somewhere. 
This formula collapses to the Kaplan-Meier in the simple case where $p(t)$ is a
vector of length 2 with state 1 = alive and state 2 = dead. 

A robust variance for the product estimate is recursive.
First, the derivative of a matrix product $AB$ is $d(A)B + Ad(B)$ where
$d(A)$ is the elementwise derivative of $A$ and similarly for $B$.
(Write out each element of the matrix product.)
Consider $U(t)$, the $n$ by $k$ matrix of per subject influence values at 
time $t$.
Since $p(t) = p(t-)H(t)$, the $i$th row of U satisfies
\begin{align}
  U_i(t) &= \frac{partial p(t)}{\partial w_i} \nonumber \\
         &= \frac{\partial p(t-)}{\partial w_i} H(t) + 
           p(t-) \frac{\partial H(t}{\partial w_i} \nonumber \\
         &= U_i(t-) H(t) +  p(t-) \frac{\partial H(t}{\partial w_i} 
           \label{ci}
\end{align}  
The first term of \mathref{ci} becomes ordinary matrix multiplication. 
For the second, notice that subject $i$ participates in only one
row of $H$, the state of said subject just prior to time $t$,
say it is state $j$.
Let $n_j(t)= \sum_i Y_{ij}(t)w_i$ be the weighted number of subjects
in state $j$, the particpants in $H_j(t)$ = row $j$ of $H$.
Using equation \mathref{H}, 
the derivative with respect to subject $i$ is $(1_i - H_j)/n_j$
where $1_i$ is a vector with 1 in the state that subject $i$ occupies
at time $t+0$.
The derivative of $H$ with respect to subject $g$
will thus be a matrix which is non-zero only for the row corresponding to the 
current state of the subject. 
Since each row of $H$ sums to a constant, each row of the deviative must
sum to zero.

The weighted sum of each column of $U$ must also be zero (if computed correctly)
and the weighted sum of squares for each column will be the infinitesimal
jackknife estimate of variance for the elements of $p$.
The entire variance-covariance matrix for the states is $U'W^2U$ where 
$W$ is a diagonal 
matrix of weights, but we currently don't report that back.
Note that this is for sampling weights.  
If one has real case weights, where an integer weight of 2 means 2 observations
that were collapsed in to one row of data to save space, then the
formula is $U'WU$.  
Case weights were somewhat common in my youth, due to small computer memory,
but I haven't seen such data in 20 years.

Below is the function for a single curve.
For the status variable a value if 0 is ``no event''.  
One nuisance in the function is that we need to ensure the
tapply command gives totals for all states, not just the ones present in the
data --- a call using the \code{subset} argument might not have all the states
--- which leads to using factor commands.
Another more confusing one is for multiple rows per subject data, where the 
cstate and U objects have only one row per subject; 
any given subject is only in one state at a time.
This leads to indices of [[atrisk]] for the set of rows in the risk set but
[[aindx]] for the subjects in the risk set, [[death]] for the rows that have
an event as some given time and [[dindx]] for the corresponding subjects.

<<survfitCI-compute-old>>=
docurve1 <- function(entry, etime, status, istate, wt, states, id) {
    ntime <- length(unique(etime))
    nstate <- length(states)
    Pmat <- matrix(0., nrow= ntime, ncol=nstate)
    vP <- Pmat  #variance
    A <- array(0., dim=c(nstate, nstate, ntime))
    uid <- sort(unique(id))
    U <- matrix(0., length(uid), nstate)  #one row per subject
    P <- as.vector(tapply(wt, factor(istate, levels=states), sum) / sum(wt))
    P <- Pmat[1,] <- ifelse(is.na(P), 0, P)
    cstate <- istate[match(uid, id)]   #current state for each observation
    
    nrisk <- integer(ntime)  #to be returned
    wrisk <- double(ntime)  #weighted number at risk
    nevent <- table(time, status>0)
    for (i in 1:ntime) {
        atrisk <- (time >=i & timeset[i] > entry)
        nrisk[i] <- sum(atrisk)
        wrisk[i] <- sum(wt[atrisk])
        tiedtime <- (time==i)
        if (nevent[i,2] ==0)  { # all censored here
            Pmat[i,] <- P
            if (i>1) {
                A[,,i] <- A[,,i-1]
                vP[i,] <- vP[i-1,]
                }
         }
        else {
            # do real work
            #  A bit of nuisance is to force tapply to give totals for all states
            aindx <- match(id[atrisk], uid)   #the id pointer for those at risk       
            ns <- as.vector(tapply(wt[atrisk], factor(cstate[aindx], levels=states),sum))
            dead <- which(tiedtime & status >0)  #the events at this time
            dindx <- match(id[dead], uid)
            nevent[i] <- length(dead)
 
            H <- tapply(wt[dead], list(factor(cstate[dindx], levels=states),
                                       factor(status[dead], levels=states)),sum)/ns
            H <- ifelse(is.na(H), 0, H) # H has NA for combinations with no representatives
            diag(H) <- 1- rowSums(H)
          
            H2 <- H
            diag(H2) <- diag(H2) -1  #version of H needed for U and A, rows sum to 0
            if (i==1) A[,,1] <- H2
            else      A[,,i] <- A[,,i-1] + H2
            newstate <- status[dead]    # where the transitions go, will never be 0
            oldstate <- cstate[dindx]   # where they came from
            U <- U%*%H   #first part of update
            
            U[aindx,] <- U[aindx,] - (P*H2/ns)[cstate[aindx], ]
            temp <- P[oldstate]/ns[oldstate]    #the extra update for the events
            U[cbind(dindx, oldstate)] <- U[cbind(dindx, oldstate)] - temp
            U[cbind(dindx, newstate)] <- U[cbind(dindx, newstate)] + temp
            cstate[dindx] <- newstate
            P <- Pmat[i,] <- c(P %*% H)
            vP[i,] <- colSums((wt[match(uid, id)] *U)^2)
        }
    }
    list(time =as.vector(timeset), pmat=Pmat, std=sqrt(vP),
         n.event= table(time, status)[,-1], n.risk= as.vector(nrisk),
         w.risk=wrisk, cumhaz=A)
}
@ 

The above function was used to work through all of my test cases, 
but is too slow in large data sets.
Rewrite it using underlying C-code, but retain the former one for
debugging purposes.  The C code appears at the end of this chapter.

The setup for (start, stop] data is a bit more work.  
We want to ensure that a subject's weight is fixed, that they have a
continuous period of observation, and that they don't
transfer from a state to itself.
The last is not strictly an error, so only warn.

<<survfitCI-idcheck>>=
if (missing(id) || is.null(id))
    stop("the id argument is required for start:stop data")

indx <- order(id, Y[,2])  #ordered event times within subject
indx1 <- indx[-length(indx)]  #a pair of lagged indices
indx2 <- indx[-1]
#if indx1[5] == index2[5] that means that the 5th and 6th are the same id
same <- (id[indx1] == id[indx2])
if (any(same & X[indx1] != X[indx2])) {
    who <- min(which(same & X[indx1] != X[indx2]))
    stop("subject is in two different groups, id ", id[indx1[who]])
}
if (any(same & Y[indx1,2] != Y[indx2,1])) {
    who <- min(which(same & Y[indx1,2] != Y[indx2,1]))
    stop("gap in follow-up, id ", id[indx1[who]])
}
if (any(Y[,1] == Y[,2])) 
    stop("cannot have start time == stop time")

if (any(same & (Y[indx1,3] == Y[indx2,3]) & (Y[indx1,3] !=0))) {
    who <-  min(which(same & (Y[indx1,3] == Y[indx2,3]) & (Y[indx1,3] !=0)))
    warning("subject changes to the same state, id ", id[indx1[who]])
}
if (any(same & weights[indx1] != weights[indx2])) {
    who <-  min(which(same & weights[indx1] != weights[indx2]))
    stop("subject changes case weights, id ", id[indx1[who]])
}

# Make the table of transitions
nst <- length(state.names)
first <- indx[!duplicated(id[indx])]
transitions <- table(factor(istate[first], 1:nst), 
                     factor(Y[first,3], 1:nstate))
if (any(same))
    transitions <- transitions + table(factor(Y[indx1[same],3], 1:nst),
                                       factor(Y[indx2[same],3], 1:nstate))
dimnames(transitions) = list(from=state.names, to=state.names[1:nstate])
@ 

<<survfitCI-startstop>>=
# We only want to pay attention to the istate variable for the very first
#  observation of any given subject, but the program logic does better with
#  a full one.  So construct one that will do this
indx <- order(Y[,2])
uid <- unique(id)
temp <- (istate[indx])[match(uid, id[indx])]  #first istate for each subject
istate <- temp[match(id, uid)]  #replicate it to full length

# Now to work
for (i in levels(X)) {
    indx <- which(X==i)
#    temp <- docurve1(Y[indx,1], Y[indx,2], status[indx], 
#                          istate[indx], weights[indx], states, id[indx])
    curves[[i]] <- docurve2(Y[indx,1], Y[indx,2], status[indx], istate[indx],
                          weights[indx], states, id[indx], se.fit, influence)
}
@ 
            
<<survfitCI-finish>>= 
# Turn the result into a survfit type object
grabit <- function(clist, element) {
    temp <-(clist[[1]][[element]]) 
    if (is.matrix(temp)) {
        do.call("rbind", lapply(clist, function(x) x[[element]]))
        }
    else {
        xx <- as.vector(unlist(lapply(clist, function(x) x[element])))
        if (class(temp)=="table") matrix(xx, byrow=T, ncol=length(temp))
        else xx
    }
}
if (length(curves) ==1) {
    keep <- c("n", "time", "n.risk", "n.event", "n.censor", "prev",
                            "p0", "std.err", "cumhaz", "influence")
    kfit <- (curves[[1]])[match(keep, names(curves[[1]]), nomatch=0)]
    kfit$transitions <- transitions
}
else {    
    kfit <- list(n =      as.vector(table(X)),  #give it labels
                 time =   grabit(curves, "time"),
                 n.risk=  grabit(curves, "n.risk"),
                 n.event= grabit(curves, "n.event"),
                 n.censor=grabit(curves, "n.censor"),
                 prev   = grabit(curves, "prev"),
                 p0     = grabit(curves, "p0"),
                 transitions = transitions,
                 strata= unlist(lapply(curves, function(x) length(x$time))))
    if (se.fit) kfit$std.err <- grabit(curves, "std.err")
    kfit$cumhaz <- array(unlist(lapply(curves, function(x) x$cumhaz)),
                           dim=c(nstate, nstate, length(kfit$time)))
}

if (influence) {
    if (length(curves) ==1) kfit$influence <- curves[[1]]$influence
    else   kfit$influence <- lapply(curves, function(x) x$influence)
}
if (all(kfit$p0 < 1)) {
    # there was an istate argument, and not everyone starts in the same
    # state, for at least one of the curves.  Add extra components.
    nstate <- length(states)
    if (se.fit) {
        sdfun <- function(x) sqrt(colSums(x^2))
        if (length(curves)==1) kfit$std0 <- sdfun(curves[[1]]$i0)
        else kfit$std0 <- matrix(unlist(lapply(curves, function(x) sdfun(x$i0))),
                            ncol=nstate, byrow=TRUE)
    }
    if (influence) {
        if (length(curves)==1) kfit$i0 <- curves[[1]]$i0
        else kfit$i0 <- do.call("rbind", lapply(curves, function(x) x$i0))
    }
}                             
@ 

Add the confidence bands.  The idea is modeled on survfitKM but with
the important differences that we are dealing with $P$ instead of $S$,
and the ``modified lower limit'' logic does not apply.
We make the assumption that $\log(1-P)$ will have better CI behavior
than $P$, with standard error of ${rm se}(P)/(1-P)$.

<<survfitCI-finish>>=
#       
# Last bit: add in the confidence bands:
#   modeled on survfit.km, though for P instead of S
#   
#
if (se.fit) {
    std.err <- kfit$std.err
    zval <- qnorm(1- (1-conf.int)/2, 0,1)
    surv <- 1-kfit$prev

    if (conf.type=='plain') {
        temp <- zval* kfit$std.err
        kfit <- c(kfit, list(lower =pmax(kfit$prev-temp, 0), 
                             upper=pmin(kfit$prev+temp, 1),
                         conf.type='plain', conf.int=conf.int))
        }

    if (conf.type=='log') {
        #avoid some "log(0)" messages
        xx <- ifelse(kfit$prev==1, 1, 1- kfit$prev)  

        temp1 <- ifelse(kfit$prev==1, NA, exp(log(xx) + zval* kfit$std.err/xx))
        temp2 <- ifelse(kfit$prev==1, NA, exp(log(xx) - zval* kfit$std.err/xx))
        kfit <- c(kfit, list(lower=pmax(1-temp1,0), upper= 1- temp2,
                         conf.type='log', conf.int=conf.int))
        }

    if (conf.type=='log-log') {
        who <- (kfit$prev==0 | kfit$prev==1) #special cases
        temp3 <- ifelse(surv==0, NA, 1)
        xx <- ifelse(who, .1,kfit$prev)  #avoid some "log(0)" messages
        temp1 <- exp(-exp(log(-log(xx)) + zval*kfit$std.err/(xx*log(xx))))
        temp1 <- ifelse(who, temp3, temp1)
        temp2 <- exp(-exp(log(-log(xx)) - zval*kfit$std.err/(xx*log(xx))))
        temp2 <- ifelse(who, temp3, temp2)
        kfit <- c(kfit, list(lower=1-temp1, upper=1-temp2,
                         conf.type='log-log', conf.int=conf.int))
        }
    }

kfit$states <- state.names
kfit$type   <- attr(Y, "type")
kfit
@

The updated docurve function is here.
One issue that was not recognized originally is delayed entry.  If most
of the subjects start at time 0, say, but one of them starts at day 100
then that last subject is not a part of $p_0$.
We will define $p_0$ as the distribution of states just before the first
event. 
The code above has already ensured that each subject has a unique
value for istate, so we don't have to search for the right one.
The initial vector and leverage are 
\begin{align*}
  p_0 &= (\sum I{s_i=1}w_i, \sum I{s_i=2}w_i, \ldots)/ \sum w_i \\
  \frac{\partial p_0}{\partial w_k} &= 
  [(I{s_k=1}, I{s_k=2}, ...)- p_0]/\sum w_i
\end{align*}

The input data set is not necessarily sorted by time or subject.
The data has been checked so that subjects don't have gaps, however.
The cstate variable has a value for each subject is their first istate
value.  Only those intervals that overlap the first event time contribute
to $p_0$.   
Now: what to report as the ``time'' for the initial row.  The values for
it come from (first event time -0), i.e. all who are at risk at the 
smallest \code{etime} with status $>0$.
But for normal plotting the smallest start time seems to be a good
default.
In the usual (start, stop] data 
a large chunk of the subjects have a common start time.
However, if the first event doesn't happen for a while
and subjects are dribbling in, then the best point to start a plot
is open to debate.  Que sera sera.
<<survfitCI-compute>>=
docurve2 <- function(entry, etime, status, istate, wt, states, id, 
                     se.fit, influence=FALSE) {
    timeset <- sort(unique(etime))
    nstate <- length(states)
    uid <- unique(id)
    index <- match(id, uid)
    first <- match(uid, id)  # first row for each subject
    cstate <- istate[first]  

    storage.mode(wt) <- "double" # just in case someone had integer weights
    # Compute p0
    if (all(status==0))  t0 <- max(etime)  #failsafe
    else t0 <- min(etime[status!=0])  # first transition event
    at.zero <- (entry < t0 & etime >= t0) 
    wtsum <- sum(wt[at.zero])  # weights for a subject may change
    p0 <- tapply(wt[at.zero], factor(istate[at.zero], levels=states), sum) /
          wtsum
    p0 <- ifelse(is.na(p0), 0, p0)  #for a state not in at.zero, tapply gives NA
    # initial leverage matrix
    if (se.fit) {
        nid <- length(uid)
        i0 <- matrix(0., nid, nstate)
        if (all(p0 <1)) {  #actually have to compute it
            who <- index[at.zero]  # this will have no duplicates
            for (j in 1:nstate) 
                i0[who,j] <- (ifelse(istate[at.zero]==j, 1, 0) - p0[j])/wtsum
            }
    }
    else i0 <- 0.  #dummy value for .Call below
    
    storage.mode(cstate) <- "integer"
    storage.mode(status) <- "integer"
    # C code has 0 based subscripts
    fit <- .Call(Csurvfitci, c(entry, etime), 
                 order(entry) - 1L,
                 order(etime) - 1L,
                 length(timeset),
                 status,
                 cstate - 1L,
                 wt,
                 index -1L,
                 p0, i0,
                 as.integer(se.fit) + 2L*as.integer(influence))

    if (se.fit) 
        out <- list(n=length(etime), time= timeset, p0 = p0, i0=i0,
             prev = fit$p, std.err=fit$std,
             n.risk = fit$nrisk,
             n.event= fit$nevent,
             n.censor=fit$ncensor,
             cumhaz=array(fit$cumhaz, dim=c(nstate,nstate, length(timeset))))
    else out <- list(n=length(etime), time= timeset, p0=p0, i0=i0,
             prev = fit$p,
             n.risk = fit$nrisk, 
             n.event = fit$nevent, 
             n.censor= fit$ncensor, 
             cumhaz=array(fit$cumhaz, dim=c(nstate,nstate, length(timeset))))
    if (influence) {
        temp <-  array(fit$influence, 
                       dim=c(length(uid), nstate, 1+ length(timeset)),
                       dimnames=list(uid, NULL, NULL))
        out$influence <- aperm(temp, c(3,2,1))
    }
    out
}
@
