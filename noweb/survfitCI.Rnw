\section{Competing risks}
\newcommand{\Twid}{\mbox{\(\tt\sim\)}}
The competing risks routine is very general, allowing subjects
to enter or exit states multiple times.
For this reason I prefer the label ``current prevalence'' estimate, 
since it estimates what fraction of the subjects are in any
given state across time.
The easiest way to understand the estimate is to consider first the
case of no censoring.  
In that setting the estimate of $F_k(t) = 1-S_k(t)$ is the number of
subjects in state $k$ at time $t$ divided by $n$, the original
sample size.
When there is censoring the conceptually simple way to extend this
is via the redistribute-to-the-right algorithm, which allocates the
case weight for a censored subject evenly to all the others in the
same state at the time of censoring.  

The literature refers to the as ``cumulative incidence'' curves,
which is confusing, but the routine name survfitCI endures.
The cannonical call is
\begin{verbatim}
  fit <- survfit(Surv(time, status, type='mstate') ~ sex, data=mine)
\end{verbatim}
 Optionally, there can be an id statement
or cluster term to indicate a data set with multiple transitions per subject.
A multi-state survival has a status variable with multiple levels,
the first of which by default is censoring, and others indicating
the type of transition that occured.
The result will be a matrix of survival curves, one for each event type.
Subjects are assumed
to start in a "null" state, which is not tabulated for survival.
To change this behavior, give subjects a transition at time 0.
  

The first part of the code is standard, parsing out options and
checking the data.
<<survfitCI>>= 
survfitCI <- function(X, Y, weights, id, istate, 
                      type=c('kaplan-meier', 'fleming-harrington', 'fh2'),
                      se.fit=TRUE,
                      conf.int= .95,
                      conf.type=c('log',  'log-log',  'plain', 'none'),
                      conf.lower=c('usual', 'peto', 'modified')){

    method <- match.arg(type)
#    error <- match.arg(error)
#    if (error != "inf")
#        warning("Only the infinetesimal jackknife error is supported for CI curves")
    conf.type <- match.arg(conf.type)
    conf.lower<- match.arg(conf.lower)

    type <- attr(Y, "type")
    if (type !='mright' && type!='mcounting' && 
        type != "right" && type != "counting")
	stop(paste("Cumulative incidence computation doesn't support \"", type,
			  "\" survival data", sep=''))

    n <- nrow(Y)
    status <- Y[,ncol(Y)]
    ncurve <- length(levels(X))
    
    state.names <- attr(Y, "states")
    if (missing(istate) || is.null(istate)) istate <- rep(0L, length(time))
    else if (is.factor(istate) || is.character(istate)) {
        # Match levels with the survival variable
        temp <- as.factor(istate)
        state.names <- unique(c(attr(Y, "states"), levels(istate)))
        istate <- as.numeric(factor(as.character(istate), levels=state.names))
    }
    else if (!is.numeric(istate) || any(istate != floor(istate)))
        stop("istate should be a vector of integers or a factor")
    
    if (length(istate) ==1) istate <- rep(istate,n)
    if (length(istate) !=n) stop ("wrong length for istate")
    states <- sort(unique(c(istate, 1:length(attr(Y, "states"))))) #list of all
    if (length(id) ==0) id <- 1:n
    
    <<survfitCI-compute>>  

    curves <- vector("list", ncurve)
    names(curves) <- levels(X)
                            
    if (ncol(Y)==2) {  # 1 transition per subject
        indx <- which(status == istate & status!=0)
        if (length(indx)) {
            warning("an observation transitions to it's starting state, ignored")
            status[indx] <- 0
        }
        if (length(id) && any(duplicated(id)))
            stop("Cannot have duplicate id values with (time, status) data")

        entry <- rep(min(0, 2*min(Y[,1])), n)
        for (i in levels(X)) {
            indx <- which(X==i)
            curves[[i]] <- docurve1(entry, Y[indx,1], status[indx], istate[indx],
                                    weights[indx], states, id[indx])
        }
    }
    else {
        <<survfitCI-startstop>>
    }

    <<survfitCI-finish>>
}
@         
        
In the multi-state case we can calculate the current prevalence
vector $p(t)$ using the product-limit form
\begin{align*}
    p(t) &= p(0)\prod_{s<=t} [I + dA(s)] \\
         &= p(0) \prod_{s<=t} H(s)
\end{align*}
Where $p$ is a row vector and $H$ is the multi-state hazard matrix.  
At each event time we define 
$$H_{jk}(t) = \sum_i w_i dN_{ijk}(t)/ \sum w_iY_{ij}{t}$$
where $N_{ijk}$ counts the number of observed trasitions between 
state $j$ and state $k$ for subject $i$, $Y_{ij}(t)$ is 1 if subject $i$ is in
state $j$ at time $t$,  $w_i$ is the weight for subject $i$, 
and 0/0 is treated as 0.
Row $j$ of $H(t)$ describes the fate of those subjects in state $j$, going from
time $t$ to time $t+0$.  
The diagonal elements of $H$ are set so that each row of $H$ sums to 1
(everyone has to go somewhere). 
This formula collapses to the Kaplan-Meier in the simple case where $P(t)$ is a
vector of length 2 with state 1 = alive and state 2 = dead. 

A complementary formula is the hazard based calculation
$$S(t) = I-P = \exp^{-A(t)} $$
where exp is the matrix exponential.
The matrix $A(t)$ has off diagonal elements $\sum_{s \le t} H(s)$, 
but the diagonal is chosen to give row sums of 0.
This collapses to $\exp(-\Lambda(t))$ in the alive/dead case.
The analog of the fh2 estimate comes from treating tied
event times of the same type (same states) as sequential.
The variance for these estimates is harder, so we haven't persued it in the
code yet.

A robust variance for the product-limit estimate is based on the
chain rule.  Consider the $n$ by $k$ matrix of per subject influence values
\begin{align}
  U_{ik}(t) &= \frac{\partial p_k(t)}{\partial w_i} \nonumber \\
            &= \frac{\partial[ p(t-) H_{.k}(t)]}{\partial w_i} \label{ci0} \\
           &= U{i.}(t-) H_{.k}(t) + 
                     p(t) \frac{\partial H_{.k}(t)}{\partial w_i} \label{ci1}\\
           &= U(t-) H(t) +  p(t) \frac{\partial H_{.k}(t)}{\partial w_i} \nonumber\\
                    
 \frac{\partial H_{jk}(t)}{\partial w_i} &=  \left\{ \begin{array}{ll}
       dN_{ijk}(t) (\sum_l w_l Y_{lj}(t))^{-1} - w_i  (\sum_l w_l Y_{lj}(t))^{-2} &
         j \ne k \\
       -\sum_{j\ne k}  \frac{\partial H_{jk}(t)}{\partial w_i} & j=k \\
       \end{array} \right. \label{ci2}
\end{align}
where $H_{.k}$ is the $k$th column of $H$.
Equation \eqref{ci0} replaces $p(t)$ with the last step of the compuation that
created it.  The next writes this out carefully using the chain rule.
The very last line is not as intimidating as it looks: since a given subject 
can only make at most 1 transition at a given time the partial for any subject
only has two elements.  
For any subject $i$ who goes from state $j$ to state $k$, 
$U_{ij}$ will decrease by the increment and $U_{ij}$ will increase.

The variance-covariance matrix for the states is $U'WU$ where $W$ is a diagonal 
matrix of case weights, but we report back only the
diagonal of this.

Below is the function for a single curve.
For the status variable a value if 0 is ``no event''.  For the state variables 0,
which is the first level of the factor, is normally the initial state.  
We compute the curve for state 0 if it is present, but that curve won't be
reported back to the user.
<<survfitCI-compute>>=
docurve1 <- function(entry, etime, status, istate, wt, states, id) {
    #
    # round off error can cause trouble: if two times are within machine
    #  precsion unique(time) and the table command will differ
    ftime <- factor(etime)
    ntime <- length(levels(ftime))
    timeset <- as.numeric(levels(ftime))
    ftime <- as.numeric(ftime)
    
    nstate <- length(states)
    Pmat <- matrix(0., nrow= ntime, ncol=nstate)
    vP <- Pmat  #variance
    uid <- unique(id)
    U <- matrix(0., length(uid), nstate)  #one row per subject
    P <- tapply(wt, factor(istate, levels=states), sum) / sum(wt)
    P <- Pmat[1,] <- ifelse(is.na(P), 0, P)
    cstate <- istate   #current state for each subject
    
    nrisk <- integer(ntime)  #to be returned
    wrisk <- double(ntime)  #weighted number at risk
    nevent <- table(ftime, status>0)
    for (i in 1:ntime) {
        atrisk <- (ftime >=i & timeset[i] > entry)
        nrisk[i] <- sum(atrisk)
        wrisk[i] <- sum(wt[atrisk])
        tiedtime <- (ftime==i)
        if (nevent[i,2] ==0)  { # all censored here
            Pmat[i,] <- P
            if (i>1) vP[i,] <- vP[i-1,]
         }
        else {
            # do real work
            #  A bit of nuisance is to force tapply to give totals for all states
            stemp <-  factor(cstate[atrisk], levels=states) 
            ns <- as.vector(tapply(wt[atrisk], stemp, sum))
            who <- which(tiedtime & status >0)  #the events at this time
            nevent[i] <- length(who)
            H <- tapply(wt[who], list(factor(cstate[who], levels=states),
                                      factor(status[who], levels=states)),sum)/ns
            H <- ifelse(is.na(H), 0, H)
            diag(H) <- 1- rowSums(H)
            P <- Pmat[i,] <- P %*% H

            newstate <- match(status[who], states)  # where the transitions go
            oldstate <- match(cstate[who], states)  # where they came from
            temp <- P[oldstate] *(1 + wt[who]/ns[oldstate]) / ns[oldstate]
            U <- U%*%H 
            indx <- match(id[who], uid)
            U[cbind(indx, oldstate)] <- U[cbind(indx, oldstate)] - temp
            U[cbind(indx, newstate)] <- U[cbind(indx, newstate)] + temp
            cstate[who] <- newstate

            vP[i,] <- colSums(wt[match(uid, id)]*U*U)
        }
    }
    browser()
    list(time =as.vector(timeset), surv=1-Pmat, std=sqrt(vP)/ifelse(vP==0, 1,Pmat), 
         n.event= as.vector(nevent[,2]), n.risk= as.vector(nrisk),
         w.risk=wrisk)
}
@ 
        
The setup for (start, stop] data is a bit more work.  
We want to ensure that a subject's weight is fixed, that they have a
continuous period of observation, and that they don't
transfer from a state to itself.

<<survfitCI-startstop>>=
if (missing(id) || is.null(id))
    stop("the id argument is required for start:stop data")

indx <- order(id, Y[,2])  #ordered event times within subject
indx1 <- c(NA, indx)  #a pair of lagged indices
indx2 <- c(indx, NA)
same <- (id[indx1] == id[indx2] & !is.na(indx1) & !is.na(indx2)) #indx1, indx2= same id?
if (any(same & X[indx1] != X[indx2])) {
    who <- 1 + min(which(same & X[indx1] != X[indx2]))
    stop("subject is in two different groups, id", (id[indx1])[who])
}
if (any(same & Y[indx1,1] != Y[indx2,2])) {
    who <- 1 + min(which(same & Y[indx1,1] != Y[indx2,2]))
    stop("gap in follow-up, id", (id[indx1])[who])
}
if (any(Y[indx1,1] == Y[indx1,2])) 
    stop("cannot have start time = stop time")

if (any(same & Y[indx1,3] == Y[indx2,3]) & Y[indx1,3] !=0) {
    who <-  1 + min(which(same & Y[indx1,1] != Y[indx2,2]))
    stop("subject changes to the same state, id", (id[indx1])[who])
}
if (any(same & weights[indx1] != weights[indx2])) {
    who <-  1 + min(which(same & weights[indx1] != weights[indx2]))
    stop("subject changes case weights, id", (id[indx1])[who])
}

for (i in levels(X)) {
    indx <- which(X==i)
    curves[i] <- docurve1(Y[indx,1], Y[indx,2], status[indx], 
                          istate[indx], weights[indx], states, id[indx])
}
@ 
            
<<survfitCI-finish>>= 
# Turn the result into a survfit type object
grabit <- function(clist, element) {
    temp <-(clist[[1]][[element]]) 
    if (is.matrix(temp)) {
        nc <- ncol(temp)
        matrix(unlist(lapply(clist, function(x) t(x[[element]]))),
                        byrow=T, ncol=nc)
        }
    else as.vector(unlist(lapply(clist, function(x) x[element])))
    }
kfit <- list(n =      grabit(curves, "n"),
             time =   grabit(curves, "time"),
             n.risk=  grabit(curves, "n.risk"),
             n.event= grabit(curves, "n.event"),
             surv   = grabit(curves, "surv"))
if (length(curves) >1)
    kfit$strata <- unlist(lapply(curves, function(x) length(x$time)))
if (se.fit) kfit$std.err <- grabit(curves, "std")/kfit$surv


#	
# Last bit: add in the confidence bands (also stolen from survfit.km)
#
if (se.fit) {
    std.err <- kfit$std.err
    #
    # n.lag = the # at risk the last time there was an event (or
    #   the first time of a strata)
    #
    events <- kfit$n.event >0
    if (ncurve==1) events[1] <- TRUE
    else           events[1 + cumsum(c(0, kfit$strata[-ncurve]))] <- TRUE
    zz <- 1:length(events)
    n.lag <- rep(kfit$n.risk[events], diff(c(zz[events], 1+max(zz))))
    std.low <- switch(conf.lower,
    		  'usual' = std.err,
    		  'peto' = sqrt((1-kfit$surv)/ kfit$n.risk),
    		  'modified' = std.err * sqrt(n.lag/kfit$n.risk))
    zval <- qnorm(1- (1-conf.int)/2, 0,1)

    if (conf.type=='plain') {
        temp1 <- kfit$surv + zval* std.err * kfit$surv
        temp2 <- kfit$surv - zval* std.low * kfit$surv
        kfit <- c(kfit, list(upper=pmin(temp1,1), lower=pmax(temp2,0),
    			 conf.type='plain', conf.int=conf.int))
        }

    if (conf.type=='log') {
        #avoid some "log(0)" messages
        xx <- ifelse(kfit$surv==0,1,kfit$surv)  

        temp1 <- ifelse(kfit$surv==0, NA, exp(log(xx) + zval* std.err))
        temp2 <- ifelse(kfit$surv==0, NA, exp(log(xx) - zval* std.low))
        kfit <- c(kfit, list(upper=pmin(temp1,1), lower=temp2,
    			 conf.type='log', conf.int=conf.int))
        }

    if (conf.type=='log-log') {
        who <- (kfit$surv==0 | kfit$surv==1) #special cases
        temp3 <- ifelse(kfit$surv==0, NA, 1)
        xx <- ifelse(who, .1,kfit$surv)  #avoid some "log(0)" messages
        temp1 <- exp(-exp(log(-log(xx)) + zval*std.err/log(xx)))
        temp1 <- ifelse(who, temp3, temp1)
        temp2 <- exp(-exp(log(-log(xx)) - zval*std.low/log(xx)))
        temp2 <- ifelse(who, temp3, temp2)
        kfit <- c(kfit, list(upper=temp1, lower=temp2,
    			 conf.type='log-log', conf.int=conf.int))
        }
    }
kfit
@
