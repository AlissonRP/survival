\section{The Fine-Gray model}
For competing risks with ending states 1, 2, \ldots $k$, 
the Fine-Gray approach turns these into a set of simple 2-state
Cox models:
\begin{itemize}
  \item (not yet in state 1) $\longrightarrow$ state 1
  \item (not yet in state 2) $\longrightarrow$ state 2
  \item \ldots
\end{itemize}
Each of these is now a simple Cox model, assuming that we are willing
to make a proportional hazards assumption.
There is one added complication:
when estimating the first model, one wants to use the data set that
would have occured if the subjects being followed for state 1 had
not had an artificial censoring, that is, had been clinically followed
as though they were still in the denominator of subjects who are at
risk of transition to state 1.
Sometimes this can be filled in directly, e.g., if we knew the enrollment
dates for each subject along with the date that follow-up for the
study was terminated, and there was no lost to follow-up (only administrative
censoring.)
In practice what is done is to estimate the overall censoring distribution and
give subjects artificial follow-up.

The function below creates a data set that can then be used with coxph.
It has a lot of commonality with \code{survSplit}.

<<finegray>>= 
finegray <- function(formula, data, weights, subset, na.action= na.pass,
                     endpoint, tstart="tstart", wt="fgwt"){
    Call <- match.call()
    indx <- match(c("formula", "data", "weights", "subset", "id"),
              names(Call), nomatch=0) 
    if (indx[1] ==0) stop("A formula argument is required")
    temp <- Call[c(1,indx)]  # only keep the arguments we wanted
    temp$na.action <- na.action
    temp[[1]] <- as.name('model.frame')  # change the function called

    special <- c("strata", "cluster")
    temp$formula <- if(missing(data)) terms(formula, special)
    else              terms(formula, special, data=data)

    mf <- eval(temp, parent.frame())
    if (nrow(mf) ==0) stop("No (non-missing) observations")
    Terms <- terms(mf)

    Y <- model.extract(mf, "response")
    if (!inherits(Y, "Surv")) stop("Response must be a survival object")
    type <- attr(Y, "type")
    if (type!='mright' && type!='mcounting')
	stop("Fine-Gray model requires a multi-state survival")
    nY <- ncol(Y)
    states <- attr(Y, "states")

    strats <- attr(Terms, "specials")$strata
    if (length(strats)) {
	stemp <- untangle.specials(Terms, 'strata', 1)
	if (length(stemp$vars)==1) strata <- mf[[stemp$vars]]
	else strata <- survival::strata(mf[,stemp$vars], shortlabel=TRUE)
        istrat <- as.numeric(strata)
	}
    else istrat <- rep(1, nrow(mf))
    
    id <- model.extract(mf, "id")
    cluster<- attr(Terms, "specials")$cluster
    if (length(cluster)) {
        if (!is.null(id)) stop("an id argument and a cluster() term are redundant")
        tempc <- untangle.specials(Terms, 'cluster', 1:10)
        ord <- attr(Terms, 'order')[tempc$terms]
        if (any(ord>1)) stop ("Cluster can not be used in an interaction")
        id <- strata(mf[,tempc$vars], shortlabel=TRUE)  #allow multiples
    }
    
    # If there is start-stop data, then there needs to be a cluster()
    #  argument or an id argument, and we check that this is indeed
    #  a competing risks form of data.
    if (type=="mcounting") {
        if (is.null(id)) stop("(start, stop] data requires a subject id")
        else {
            index <- order(id, Y[,2]) # by time within id
            temp <- Y[index,]
            first <- which(!duplicated(id[index]))
            last  <- c(first[-1] -1, length(id))
            if (any(temp[-last, 3]) != 0)
                stop("a subject has a transition before their last time point")
            delta <- c(temp[-1,1], 0) - temp[,2]
            if (any(delta[-last] !=0)) stop("a subject has gaps in their fu time")
        }
    }

    if (missing(endpoint)) enum <- 1  #generate a data set for which endpoint?
    else {
        index <- match(endpoint, states)
        if (any(is.na(index)))
            stop ("endpoint argument has a state that is not in the data")
        enum <- index[1]
        if (length(index) > 1) warning("only the first endpoint was used")
    }
        
    # Did the user hand me a Surv call with multiple variables, or a
    #  premade Surv object?
    if (class(formula[[2]]) == "call" && formula[[2]][[1]]== as.name("Surv")){
        # it was a call, figure out the names
        # The user might have used something like Surv(status=abc, time=fred),
        #  so use match.call to resolve it.
        was.a.call <- TRUE
        temp <- match.call(Surv, formula[[2]])
        for (i in c("time", "time2", "event")) {
            if (!(is.null(temp[[i]]) || is.name(temp[[i]])))
                stop("cannot deal with complex arguments within a Surv call")
        }
        if (nY ==2) {
            end <- as.character(temp$time)
            if (is.null(temp$status)) event <- as.character(temp$time2)
            else event <- as.character(temp$event)
        }
        else {
            tstart <- as.character(temp$time)
            end   <-  as.character(temp$time2)
            event <-  as.character(temp$event)
            }
    }
     else {
        if (class(formula[[2]]) != "name")
            stop("left hand side not recognized")
        was.a.call <- FALSE
        survname <-as.character(formual[[2]])
    }
    <<finegray-censor>>   
    <<finegray-build>>
}  
@

The censoring distribution is estimated as a simple KM with one modification.
In a time to death KM say that subject A has an event and subject B is censored
on the exact same day.  We assume that B was at risk for said event when 
computing the estimate.  The set of subjects at risk is left continuous
and the estimated survival is right-continuous.
For the reverse case of computing the censoring distribution, the FG estimate
does not assume that subject A was at risk of censoring on that day.
The risk set is right-continuous and the function left continuous.
A fix to this is break any ties by making
all the event times just a little bit shorter.
To avoid issues with times that are nearly identical (but not quite) we first
convert to an integer time scale.
Since this is a competing risks data set any non-censored observation for a
subject is their last, so this time shift does not goof up the alignment
of start, stop data.

<<finegray-censor>>=
find2 <- function(x, vec, left.open=FALSE, ...) {
    if (!left.open) findInterval(x, vec, ...)
    else {
        # the left.open arg is a recent addition to findInterval, and I want
        #  this to work in 3.2.0 (institutional installs).  In another cycle or
        #  so we can drop this workaround
        #
        2 + length(x) - findInterval(-x, rev(-vec), ...)
    }
}
    
if (ncol(Y) ==2) {
    temp <- min(Y[,1], na.rm=TRUE)
    if (temp >0) zero <- 0
    else zero <- 2*temp -1  # a value less than any observed y
    Y <- cbind(zero, Y)  # add a start column
}
utime <- sort(unique(Y[,2]))  # all the unique end times
newtime <- matrix(findInterval(Y[,1:2], utime), ncol=2) 
status <- Y[,3]
newtime[status !=0, 2] <- newtime[status !=0,2] - .2
csurv <- survfit(Surv(newtime[,1], newtime[,2], status==0) ~ istrat)
@ 

Consider the following data set: 
\begin{itemize}
  \item Events of type 1 at times 1, 4, 5,  10
  \item Events of type 2 at times 2, 5, 8
  \item Censors at times 3, 4, 4, 6, 8, 9, 12
\end{itemize}
The censoring distribution will have the following shape:
\begin{center}
  \begin{tabular}{rcccccc}
    interval& (0,3]& (3,4] & (4,6]         & (6,8]       & (8,12] & 12+\\
    C(t)    &  1   &11/12  & (11/12)(8/10) & (11/15)(5/6)&  (11/15)(5/6)(3/4)&
       0 \\
       & 1.0000 & .9167 & .7333 & .6111 & .4583
    \end{tabular}
  \end{center}
Notice that at time 4, the event at time 4 is not counted in the risk set
so the jump is 8/10 rather than 8/11. Likewise at time 8 the risk set has 4 instead
of 5.  Censors occur after deaths.
Though there are 6 unique weights, 
in the created data set for event type 1 we only need to know case
weights at times 1, 4, 5, and 10.
To make a minimal size data set the weight are defined over intervals of (0,1],
(1,5] and (5,10].

The subject who has an event of type 2 at time 2, before the first censoring,
will get all 3 intervals with weights of 1, .9167, and .4583.
The event at time 5 has a weight of 1 in the first two intervals and 
.4583/.7333 = (5/6)(3/4) in the third; their censoring distribution starts
at time 5+.  The event at time 8 has a weight of 1 for all intervals.

<<finegray-build>>=
status <- Y[, 3]

stratfun <- function(i) {
    if (dim(csurv) >1) temp <- csurv[i]  # censoring curve for this stratum
    else temp <- csurv   # skip the subscript to avoid a warning message
    ctime <- utime[temp$time[temp$n.event >0]]
    cprob <- temp$surv[temp$n.event >0]
    
    keep <- which(istrat ==i)
    tdata <- mf[istrat ==i, -1, drop=FALSE]
    times <- sort(unique(Y[keep & status == enum, 2])) #unique event times 
    if (length(times)==0) return(tdata)  #no events in this stratum

    index <- pmin(length(times), find2(times, ctime, left.open=TRUE))
    # times before the first ctime get index 0, those between 1 and 2 get 1, etc
    # find the max time in each interval.  Since times are ordered, I want
    # the last appearance of each unique index 
    index2 <- rev(!duplicated(rev(index)))
    # times[index2] will be the cutpoints = event times at which unique weight
    #  applies.  probs will be the censoring distribution at those times
    cuts <- times[index2]
    probs <- c(1.0, cprob)[1+ index[index2]]  
browser()
    expand <- (Y[keep, 3] !=0 & Y[keep,3] != enum) #which rows to expand
    split <- .Call("finegray", Y[keep,1], Y[keep,2], as.double(cuts), 
                   probs, expand, ctime, cprob)
browser()
    tdata <- tdata[split$row,,drop=FALSE]
    tstat <- ifelse(status[split$row]== enum, 1, 0)
    tstat[split$censor] <- censor
    if (was.a.call) {
        tdata[[tstart]] <- split$start
        tdata[[end]]    <- split$end
        tdata[[event]]  <- tstat
    }
    else tdata[[sname]] <- Surv(split$start, split$end, tstat)
    tdata[[wt]] <- split$wt
    tdata
}

if (max(istrat) ==1) result <- stratfun(1)
else {
    tlist <- lapply(1:max(istrat), stratfun)
    result <- do.call("rbind", tlist)
}

rownames(result) <- NULL   #remove all the odd labels that R adds
attr(result, "event") <- states[enum]
result
@ 
