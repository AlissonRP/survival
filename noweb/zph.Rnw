\section{The cox.zph function}
The simplest test of proportional hazards is to use a time dependent
coefficient $\beta(t) = a + bt$.
Then $\beta(t) x = ax + b*(tx)$, and the extended coefficients $a$ and $b$
can be obtained from a Cox model with an extra 'fake' covariate $tx$.
More generally, replace $t$ with some function $g(t)$, which gives rise to
an entire family of tests.
An efficient assessment of this extended model can be done using a score
test.
\begin{itemize}
  \item Augment the original variables $x_1, \ldots x_k$ with $k$ new ones
$g(t)x_1, \ldots, g(t)x_k$
  \item Compute the first and second derivatives $U$ and $H$ of the Cox model
at the starting estimate of $(\hat\beta, 0)$; prior covariates at their
prior values, and the new covariates at 0.  No iteration is done.
This can be done efficiently with a modified version of the primary C routines
for coxph.
  \item By design, the first $k$ elements of $U$ will be zero. Thus the 
first iteration of the new coefficients, and the score tests for them, are
particularly easy.  
\end{itemize}

The information or Hessian matrix for a Cox model is 
$$ \sum_{j \in deaths} V(t_j)  = \sum_jV_j$$
where $V_j$ is the variance matrix of the weighted covariate values, over
all subjects at risk at time $t_j$.
Then the expanded information matrix for the score test is
\begin{align*}
  H &= \left(\begin{array}cc  H_1 & H_2 \\ H_2' & H_3 \end{array} \right) \\
  H_1 &= \sum V(t_j) \\
  H_2 &= \sum V(t_j) g(t_j) \\
  H_3 &= \sum V(t_j) g^2(t_j)
\end{align*}
The inverse of the matrix will be more numerically stable if $g(t)$ is centered
at zero, and this does not change the test statistic.
In the usual case $V(t)$ is close to constant in time --- the variance of
$X$ does not change rapidly --- and then $H_2$ is approximately zero.
The original cox.zph used an approximation, which is to assume that
$V(t)$ is exactly constant.
In that case $H_2=0$ and $H_3= \sum V(t_j) \sum g^2(t_j)$ and the test
is particularly easy to compute.
This assumption of identical components can fail badly for models with a
covariate by strata interaction, and for some models with covariate
dependent censoring.
Multi-state models finally forced a change.

The newer version of the routine has two separate tracks: for the formal test
and another for the residuals.

<<cox.zph>>=
cox.zph <- function(fit, transform='km', terms=TRUE, single=TRUE, global=TRUE) {
    call <- match.call()
    if (!inherits(fit, 'coxph')) stop ("Argument must be the result of coxph")
    if (inherits(fit, 'coxph.null'))
	stop("The are no score residuals for a Null model")

    cget <- coxph.getdata(fit, y=TRUE, x=TRUE, stratax=TRUE, weights=TRUE)
    y <- cget$y
    ny <- ncol(y)
    if (length(cget$strata)) istrat <- cget$strata
    else istrat <- rep(1L, nrow(y))

    sresid <- resid(fit, 'schoenfeld')
    varnames <- names(fit$coefficients)
    nvar <- length(varnames)
    ndead<- length(sresid)/nvar
  
    #if (nvar==1) times <- as.numeric(names(sresid))
    #else         times <- as.numeric(dimnames(sresid)[[1]])

    <<zph-transform>>
    <<zph-terms>>

    return(rlist)
}
@ 

The user can use $t$ or $g(t)$ as the multiplier of the covariates.
The default is to use the KM, only because that seems to be best at
avoiding edge cases.

<<zph-transform>>=
if (is.character(transform)) {
    tname <- transform
    ttimes <- switch(transform,
                     'identity'= 
                     'rank'    = rank(times),
                     'log'     = log(times),
                     'km' = {
                         temp <- survfitKM(factor(rep(1L, nrow(y))),
                                           y, se.fit=FALSE)
                         # A nuisance to do left cont KM
                         t1 <- temp$surv[temp$n.event>0]
                         t2 <- temp$n.event[temp$n.event>0]
                         km <- rep(c(1,t1), c(t2,0))
                         if (is.null(attr(sresid, 'strata')))
                             1-km
                         else (1- km[sort.list(sort.list(times))])
                     },
                     stop("Unrecognized transform"))
	}
    else {
	tname <- deparse(substitute(transform))
        if (length(tname) >1) tname <- 'user'
	ttimes <- transform(times)
	}
    gtime <- ttimes - mean(ttimes) 
browser()
    # Now get the scores and variance matrix
    if (ny==2) {
        ord <- order(istrat, y[,1])
        scores <- .Call(Czph1, gtime, y, cget$x, fit$linear.predictor,
                        cget$weights, istrat, fit$method, ord-1L)
    }
    else {
        ord <- order(istrat, y[,2])
        scores <- .Call(Czph2, xx, y, cget$x, fit$linear.predictor,
                        cget$wegints, istrata, fit$method, ord)
    }
browser()
@

The result has a score vector of length $2p$ where $p$ is the number of
variables and an information matrix that is $2p$ by $2p$.
This is done with C code that
is a simple variation on iteration 1 for a coxph model.

If \code{terms=TRUE}, the default, then do tests on each term separately.
If \code{single} is TRUE then treat each of them as a single degree of
freedom test, otherwise as a multi-degree of freedom.
If all the variables are continuous this is all a moot point.

<<zph-terms>>=
asgn <- fit$assign
nterm <- length(asgn)   # asgn will be 1, 2,2,2, 3, etc
test <- rho <- double(nterm)
df   <- rep(1L, nterm)
for (ii in unique(asgn)) {
    jj <- which(asgn==ii) + ncoef
    contr <- rep(0, 2*ncoef)
    if (length(jj) ==1) contr[jj] <- score$score[jj]
    else if (single) contr[jj] <- score$score[jj]
    else {
        df[ii] <- length(jj)
        contr <- matrix(0, ncol=length(jj), nrow=2*ncoef)
        for (k in 1:length(jj)) contr[jj[k], k] <- score$score[jj[k]] 
    }
    if (df[ii]==1) test[ii] <- score[jj]^2/score$imat[jj,jj]
    test[ii] <- c(solve(score$imat[jj,jj], score) %*% score)
}

rval <- list(test=test, df=df)
@ 


