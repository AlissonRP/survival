\section{The cox.zph function}
The simplest test of proportional hazards is to use a time dependent
coefficient $\beta(t) = a + bt$.
Then $\beta(t) x = ax + b*(tx)$, and the extended coefficients $a$ and $b$
can be obtained from a Cox model with an extra 'fake' covariate $tx$.
More generally, replace $t$ with some function $g(t)$, which gives rise to
an entire family of tests.
An efficient assessment of this extended model can be done using a score
test.
\begin{itemize}
  \item Augment the original variables $x_1, \ldots x_k$ with $k$ new ones
$g(t)x_1, \ldots, g(t)x_k$
  \item Compute the first and second derivatives $U$ and $H$ of the Cox model
at the starting estimate of $(\hat\beta, 0)$; prior covariates at their
prior values, and the new covariates at 0.  No iteration is done.
This can be done efficiently with a modified version of the primary C routines
for coxph.
  \item By design, the first $k$ elements of $U$ will be zero. Thus the 
first iteration of the new coefficients, and the score tests for them, are
particularly easy.  
\end{itemize}

The information or Hessian matrix for a Cox model is 
$$ \sum_{j \in deaths} V(t_j)  = \sum_jV_j$$
where $V_j$ is the variance matrix of the weighted covariate values, over
all subjects at risk at time $t_j$.
Then the expanded information matrix for the score test is
\begin{align*}
  H &= \left(\begin{array}{cc}  H_1 & H_2 \\ H_2' & H_3 \end{array} \right) \\
  H_1 &= \sum V(t_j) \\
  H_2 &= \sum V(t_j) g(t_j) \\
  H_3 &= \sum V(t_j) g^2(t_j)
\end{align*}
The inverse of the matrix will be more numerically stable if $g(t)$ is centered
at zero, and this does not change the test statistic.
In the usual case $V(t)$ is close to constant in time --- the variance of
$X$ does not change rapidly --- and then $H_2$ is approximately zero.
The original cox.zph used an approximation, which is to assume that
$V(t)$ is exactly constant.
In that case $H_2=0$ and $H_3= \sum V(t_j) \sum g^2(t_j)$ and the test
is particularly easy to compute.
This assumption of identical components can fail badly for models with a
covariate by strata interaction, and for some models with covariate
dependent censoring.
Multi-state models finally forced a change.

The newer version of the routine has two separate tracks: for the formal test
and another for the residuals.

<<cox.zph>>=
cox.zph <- function(fit, transform='km', singledf =TRUE, global=TRUE) {
    Call <- match.call()
    if (!inherits(fit, 'coxph')) stop ("Argument must be the result of coxph")
    if (inherits(fit, 'coxph.null'))
	stop("The are no score residuals for a Null model")

    cget <- coxph.getdata(fit, y=TRUE, x=TRUE, stratax=TRUE, weights=TRUE)
    y <- cget$y
    ny <- ncol(y)
    event <- (y[,ny] ==1)
    if (length(cget$strata)) istrat <- cget$strata - 1L  # number from 0, for C
    else istrat <- rep(0L, nrow(y))

    sresid <- resid(fit, 'schoenfeld')
    varnames <- names(fit$coefficients)
    nvar <- length(varnames)
    ndead<- length(sresid)/nvar
  
    #if (nvar==1) times <- as.numeric(names(sresid))
    #else         times <- as.numeric(dimnames(sresid)[[1]])

    <<zph-transform>>
    <<zph-terms>>
    <<zph-schoen>>

    rval$call <- Call
    rval$transform <- transform
    class(rval) <- "cox.zph"
    return(rval)
}

print.cox.zph <- function(x, digits = max(options()$digits - 4, 3),
                          signif.stars=FALSE, ...)  {
    invisible(printCoefmat(x$table, digits=digits, signif.stars=signif.stars, 
                           P.values=TRUE, has.Pvalue=TRUE, ...))
}
@ 

The user can use $t$ or $g(t)$ as the multiplier of the covariates.
The default is to use the KM, only because that seems to be best at
avoiding edge cases.

<<zph-transform>>=
times <- y[,ny-1]
if (is.character(transform)) {
    tname <- transform
    ttimes <- switch(transform,
                     'identity'= times,
                     'rank'    = rank(times),
                     'log'     = log(times),
                     'km' = {
                         temp <- survfitKM(factor(rep(1L, nrow(y))),
                                           y, se.fit=FALSE)
                         # A nuisance to do left cont KM
                         indx <- findInterval(times, temp$time, left.open=TRUE)
                         1.0 - c(1, temp$surv)[indx+1]
                     },
                     stop("Unrecognized transform"))
	}
    else {
	tname <- deparse(substitute(transform))
        if (length(tname) >1) tname <- 'user'
	ttimes <- transform(times)
	}
    gtime <- ttimes - mean(ttimes[event]) 

    # Now get the U, information, and residuals
    if (ny==2) {
        ord <- order(istrat, y[,1]) -1L
        resid <- .Call(Czph1, gtime, y, cget$x, fit$linear.predictors,
                        cget$weights, istrat, fit$method=="efron", ord)
    }
    else {
        ord1 <- order(-istrat, -y[,1]) -1L   # reverse time for zph2
        ord2 <- order(-istrat, -y[,2]) -1L
        resid <- .Call(Czph2, gtime, y, cget$x, fit$linear.predictors,
                        cget$weights, istrat, fit$method=="efron", 
                        ord1, ord2)
    }
@

The result has a score vector of length $2p$ where $p$ is the number of
variables and an information matrix that is $2p$ by $2p$.
This is done with C code that
is a simple variation on iteration 1 for a coxph model.

If \code{singledf} is TRUE then treat each term as a single degree of
freedom test, otherwise as a multi-degree of freedom.
If all the variables are univariate this is a moot point.
The survival routines return Splus style assign components.

<<zph-terms>>=
asgn <- fit$assign
if (is.list(asgn)) {
    termname <- names(asgn)
    nterm <- length(asgn)   # asgn will be 1, 2,2,2, 3, etc
} else stop ("unexpected assign component")
if (any(is.na(fit$coefficients))) {
    # fix up assign so as to ignore missing coefs, this should be rare
    mcoef <- which(is.na(fit$coefficients))
    asgn <- lapply(asgn, function(i) i[!(i %in% mcoef)])
    asgn <- asgn[sapply(asgn, length)>0]  # drop any that were lost
    termname <- names(asgn)
    nterm <- length(asgn)   # asgn will be 1, 2,2,2, 3, etc
}
                   
test <- double(nterm+1)
df   <- rep(1L, nterm+1)
u0 <- rep(0, nvar)

for (ii in 1:nterm) {
    jj <- asgn[[ii]]
    kk <- c(1:nvar, jj+nvar)
    imat <- resid$imat[kk, kk]
    u <- c(u0, resid$u[jj+nvar])
    if (singledf && length(jj) >1) {
        vv <- solve(imat)[-(1:nvar), -(1:nvar)]
        t1 <- sum(fit$coef[jj] * resid$u[jj+nvar])
        test[ii] <- t1^2 * (fit$coef[jj] %*% vv %*% fit$coef[jj])
        df[ii] <- 1
    }
    else {
        test[ii] <- drop(solve(imat,u) %*% u)
        df[ii] <- length(jj)
    }
}

#Global test
test[nterm+1] <- solve(resid$imat, resid$u) %*% resid$u
df[nterm+1]   <- nvar

tbl <- cbind(test, df, pchisq(test, df, lower.tail=FALSE))
dimnames(tbl) <- list(c(termname, "GLOBAL"), c("chisq", "df", "p"))
rval <- list(table=tbl, x=sort(gtime[event]), time=sort(y[event, ny-1]))
@ 

The matrix of scaled Schoenfeld residuals is created one stratum at a
time. 
The ideal for the residual $r(t_i)$, contributed by an event for subject
$i$ at time $t_i$ is to use $r_iV^{-1}(t_i)$, the inverse of the  variance 
matrix of $X$ at that time and for the relevant stratum.
What is returned as \code{resid\$imat} is $\sum_i V(t_i)$.
One option would have been to return all the individual $\hat V_i$ matrices,
but that falls over when the number at risk is too small and it cannot
be inverted.
Option 2 would be to use a per stratum averge of the $V_i$, but that falls
flat for models with a large number of strata, a nested case-control model
for instance. 
We take a different average that may not be the best, but seems to be
good enough and doesn't seem to fail.
\begin{enumerate}
  \item The \code{resid\$used} matrix contains the number of deaths for
    each strata (row) the contributed to the sum for each variable (column).
    The value is either 0 or the number of events in the stratum, zero for those
    variables that are constant within the stratum.  From this we can get the
    number of events that contributed to each element of the \code{imat} total.
    Dividing by this gives a per-element average \code{vmean}.  
  \item For a given stratum, some of the covariates may have been unused.  For
    any of those set the scaled Schoenfeld residual to NA, and use the other
    rows/columns of the \code{vmean} matrix to scale the rest.
\end{enumerate}
Now if some variable $x_1$ has a large variance at some time points and a
small variance at others, or a large variance in one stratum and a small
variance in another, the above smoothing won't catch that subtlety.
However we expect such an issue to be rare. 
The common problem of time*covariate interactions is the target of the
above manipulations.

<<zph-schoen>>=
# Make the weight matrix
wtmat <- matrix(0, nvar, nvar)
for (i in 1:nrow(resid$used))
    wtmat <- wtmat + outer(resid$used[i,], pmin(resid$used[i,], 1), '*')
vmean <- resid$imat[1:nvar, 1:nvar]/wtmat

sresid <- resid$schoen
if (singledf && any(sapply(asgn, length) > 1)) { # collase multi-column terms
    temp <- matrix(0, ncol(sresid), nterm)
    used <- matrix(0, nrow(resid$used), nterm)
    for (i in 1:nterm) {
        j <- asgn[[i]]
        temp[j, i] <- 1
        for (k in 1:nrow(used)) 
            used[k,i] <- max(resid$used[k, j])
    }     
    sresid <- sresid %*% temp
    vmean <- t(temp) %*% vmean %*% temp
    colnames(sresid) <- names(asgn)
}
else {
    keep <- !is.na(fit$coefficients)
    used <- resid$used[,keep, drop=FALSE]
    colnames(sresid) <- names(fit$coefficients)[keep]
    vmean <- vmean[keep, keep]
}

# for each stratum, rescale the observations in that stratum
sgrp <- rep(1:nrow(resid$used), apply(resid$used, 1, max))
for (i in 1:nrow(used)) {
    k <- (used[i,] > 0)
    j <- which(sgrp==i)
    sresid[j, k] <- t(solve(vmean[k, k], t(sresid[j, k])))
    sresid[j, !k] <- NA
} 
rval$y <- sresid
rval$var <- solve(vmean)  
@ 

<<cox.zph>>=
"[.cox.zph" <- function(x, ..., drop=FALSE) {
    i <- ..1
    z<- list(table=x$table[i,,drop=FALSE], x=x$x, time= x$time, 
                y = x$y[,i,drop=FALSE],
		var=x$var[i,i, drop=FALSE], call=x$call,
		transform=x$transform)
    attributes(z) <- attributes(x)
    z
    }
@
