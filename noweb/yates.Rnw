\section{Linear models and contrasts}
The primary contrast function is \code{yates}.  
This function does both simple and population contrasts; the name is a nod
to the ``Yates weighted means'' method, the first population contrast that
I know of.  
A second reason for the name is that
the word ``contrast'' is already overused in the S/R lexicon.
Both \code{yates}  and \code{cmatrix} can be used with any model that returns 
the necessary
portions, e.g., lm, coxph, or glm.
They were written because I became embroiled in the ``type III'' controversy,
and made it a goal to figure out what exactly it is that SAS does. 
If I had known that that quest would take multiple years would 
perhaps have never started.

Population contrasts can result in some head scratching.
It is easy to create the predicted value for any hypothethical
subject from a model.  
A population prediction holds some data values constant and lets the
others range over a population, giving a mean predicted value or
population average.  
Population predictions for two treatments are the familiar g-estimates
of causal models. 
We can take sums of differences of these predictions as well, e.g. to
ask if they are significantly different.
What can't be done is to work backwards from one of these contrasts to the
populations, at least for continuous variables.
If someone asks for an x contrast of 15-5 is this a sum of two population
estimates at 15 and -5, or a difference?  
It's always hard to guess the mind of a user.

First is cmatrix routine.  This is called by users to create a contrast
matrix for a model, users can also construct their own contrast matrices.
The routine requires a fit and a term; the default test will be for
the entire term.  The result will be a matrix or list that has a label
attribute containing the name of the term; this is used in printouts in the
obvious way.
Suppose that our model was \code{coxph(Surv(time, status) ~ age*sex + ph.ecog)}.
Someone might want the matrix for the age, sex, age*sex (2 df),
age:sex or ph.ecog term.
The first task is to parse the user's formula and match it to the terms
structure found in the data: we should be a proper subset of it.
  
<<yates>>=
cmatrix <- function(fit, term, 
                    type=c("full", "linear", "linear2", "pairwise")){
    # If any of the parts I need are missing, then likely the first are
    #  is not a model fit
    if (missing(fit)) stop("a fit argument is required")
    Terms <- try(terms(fit), silent=TRUE)

    if (inherits(Terms, "try-error"))
        stop("the fit does not have a terms structure")
    else Terms <- delete.response(Terms)   # y is not needed
    Tatt <- attributes(Terms)
    
    # a function that allows them to refer to terms by name or by number
    matchterm <- function(x) {
        nlab <- length(term.label)
        index <- pmatch(x, c(term.label, 1:nlab), nomatch=0) 
        index <- ifelse(index > nlab, index-nlab, index)
        c("", term.label)[1+index]
    }

    if (missing(term)) stop("a term argument is required")
    if (is.character(term)) term <- formula(paste("~", term))
    else if (is.numeric(term)) {
        if (all(term == floor(term) & term >0 & term < length(Tatt$term.labels)))
            term <- formula(paste("~", 
                                  paste(Tatt$term.labels[term], collapse='+')))
        else stop("a numeric term must be an integer between 1 and max terms in the fit")
        }
    else if (!inherits(term, "formula"))
        stop("the term must be a formula, character string, or integer")
    fterm <- delete.response(terms(term))
    fatt <- attributes(fterm)
    indx <- match(fatt$term.labels, Tatt$term.labels)
    if (any(is.na(indx))) {
        # allow partial matching.  If the fit had factor(x) but we have "x",
        #  pretend we said "factor(x)".  Fail for ns(x) + log(x) though.
        temp <- fatt$term.labels
        for (i in 1:length(temp)) {
            j <- grep(temp[i], Tatt$term.labels)
            if (length(j)==1) temp[i] <- Tatt$term.labels[j]
            else stop("test term not found in the fit")
            }
        fterm <- terms(formula( paste("~", paste(temp, collapse="+"))))
        fatt <- attributes(fterm)
        indx <- match(fatt$term.labels, Tatt$term.labels)
   }
    
    # match these up with the columns via the assign attribute
    assign <- fit$assign
    if (missing(assign)) stop("the fit is missing an assign component")
    if (is.list(assign)) {
        # old style assign as used in Splus, and still used in coxph
        assign <- rep(1:length(assign), sapply(assign, length))
    }
    ncoef <- length(assign)
    whichcol <- which(assign %in% indx & !is.na(coef(fit)))
    ntest <- length(whichcol)
    if (ntest ==0) stop("no non-missing coefficients in the estimate")
    termname <- fatt$term.labels[indx]  # to label the output
    
    # Now build the matrix
    <<cmatrix-build>>
    # return the result
    attr(cmat, "label") <- termname
    cmat
}
@ 

Building the contrast matrix is very easy for type=full; it is simply
a test of ``are all these coefficients zero''.
The \code{pairwise} option creates a set of contrast matrices for all pairs
of a factor.
The  \code{linear} option is of interest for terms that have more than one
column; the two most common cases are a factor variable or a spline.
The \code{linear2} form returns a pair of tests, one for the linear and one
for the nonlinear part.  For non-linear functions such as splines we need
some notion of the range of the data, since we want to be linear over the
entire range.  

<<cmatrix-build>>=
type <- match.arg(type)
cmat <- matrix(0., nrow= ntest, ncol=ncoef)
for (i in 1:ntest) cmat[i, whichcol[i]] <- 1
dimnames(cmat)[[2]] <- names(coef(fit))

# All of the other transformations require a single term, no interactions
tlab <- fatt$term.labels
if (type != "full" && length(tlab) > 1)
    stop(test, " tests must be for a single term")
# is it a factor?
isfac <- (!is.null(fit$xlevels) && !is.na(match(tlab, names(fit$xlevels))))
@ 
 
R models do extra processing for factors and intercepts.  Consider a
model \code{x1 + x2 -1} as the right hand side
where x1 and x2 are factors.  
The first term ends up as 3 columns and the second as 2. 
We have to apply the intercept issue to only first terms.

<<cmatrix-build>>=
if (type == "pairwise") {
    if (!isfac) stop("pairwise tests are only valid for categorical predictors")
    if (is.null(fit$contrasts)) stop("fit has no contrasts component")

    i <- match(tlab, names(fit$xlevels))
    if (i ==1 && attr(Terms, "intercept")==0) 
         temp <- get(fit$contrasts[[tlab]])(fit$xlevels[[tlab]], contrast=FALSE)
    else temp <- get(fit$contrasts[[tlab]])(fit$xlevels[[tlab]])
    
    nlev <- nrow(temp)   # number of levels of the factor
    ncon <- (nlev * (nlev-1))/2 #number of contrasts
    cmat <- vector("list", ncon)
    cname <- character(ncon)
    lname <- fit$xlevels[[tlab]]
    tmat <- matrix(0, 1, ncoef, dimnames=list(NULL, names(coef(fit))))
    k <- 1
    for (i in 1:(nlev-1)) {
        for (j in (i+1):nlev) {
            cname[k] <- paste(lname[i], lname[j], sep=" vs ")
            cmat[[k]] <- tmat
            cmat[[k]][whichcol] <- temp[i,] - temp[j,]
            k <- k+1
        }
    }
    names(cmat) <- cname
    # Add the overall test
    attr(cmat, "global") <- TRUE
}
@ 
    
The linear transform works for factors and splines.  It would in theory
work for polynomial terms as well, but I don't know a good way to pick
a range.  For splines, a function that is linear on the midpoints of the
knots will give a linear fit.

<<cmatrix-build>>=
else if (type=="linear" || type== "linear2") {
    if (isfac) cmat[1, whichcol] <- 1:length(whichcol)
    else {
        # Look up  the call
        tindx <- match(tlab, Tatt$term.labels)
        tcall <- Tatt$predvars[[tindx + 1]]  # skip the 'call' 
        if (tcall[[1]] == "pspline") cmat[1, whichcol] <- 1:length(whichcol)
        else if (tcall[[1]] %in% c("poly", "ns")) cmat[1, whichcol[1]] <- 1
        else if (tcall[[1]] %in% c("ns", "bs") && any(names(tcall) == "knots")) {
            # it is a spline
            knots <- sort(c(tcall[["knots"]], tcall[["Boundary.knots"]]))
            xx <- sort(c(knots, knots[-length(knots)] + diff(knots)/2))
            yy <- 1:length(xx)
            tcall[[2]] <- xx
            tfit <- lm(yy ~ eval(tcall))
            cmat <- cmat[1, whichcol] <- coef(tfit)[-1]
        } 
        else stop("don't know how to do a linear contrast for this term")
    }
    if (type=="linear") cmat <- cmat[1,, drop=FALSE]
    else {
        stop("not done")
    }
}
else if (type != "full") stop("unrecognized type")
@ 


Here are some helper routines.
Formulas are from chapter 5 of Searle.  The sums of squares only makes
sense within a linear model.
<<yates>>=
gsolve <- function(mat, y, eps=sqrt(.Machine$double.eps)) {
    # solve using a generalized inverse
    # this is very similar to the ginv function of MASS
    temp <- svd(mat, nv=0)
    dpos <- (temp$d > max(temp$d[1]*eps, 0))
    dd <- ifelse(dpos, 1/temp$d, 0)
    # all the parentheses save a tiny bit of time if y is a vector
    if (all(dpos)) x <- drop(temp$u %*% (dd*(t(temp$u) %*% y)))
    else if (!any(dpos)) x <- drop(temp$y %*% (0*y)) # extremely rare
    else x <-drop(temp$u[,dpos] %*%(dd[dpos] * (t(temp$u[,dpos, drop=FALSE]) %*% y)))
    attr(x, "df") <- sum(dpos)
    x
}

qform <- function(var, beta) { # quadratic form b' (V-inverse) b
    temp <- gsolve(var, beta)
    list(test= sum(beta * temp), df=attr(temp, "df"))
}
cfun <- function(cmat, beta, varmat, sigma2) {
    estimate <- drop(cmat %*% beta)  #vector of contrasts
    ss <- qform(cmat %*% varmat %*% t(cmat), estimate)
    evar <- drop(cmat %*% varmat %*% t(cmat)) #variance of the estimate
    rval <- list(estimate=estimate, var=evar, test=ss$test, df=ss$df)
    if (!is.null(sigma2)) rval$ss <- ss$test*sigma2
    rval
}
@ 

Now for the primary function.

<<yates>>=
yates <- function(fit, test, population=c("none", "data", "factorial", "sas"),
                  method=c("direct", "stt", "nstt"), 
                  ss, ...) {
    if (missing(fit)) stop("a fit argument is required")
    Terms <- try(terms(fit), silent=TRUE)
    if (inherits(Terms, "try-error"))
        stop("the fit does not have a terms structure")
    else Terms <- delete.response(Terms)   # y is not needed
    Tatt <- attributes(Terms)
    
    if (is.character(population)) {
        population <- match.arg(population)
        if (population != "none") mf <- stats::model.frame(fit)
    }
    else {
        if (!inherits(population, "data.frame"))
            stop("the population argument must be a data frame or character")
        # treat it like the newdata argument of a predict call.
        mf <- stats::model.frame(Terms, population, xlev=fit$xlevels)
        if (!is.null(cl <- attr(Terms, "dataClasses")))
            .checkMFClasses(cl, mf)
        population <- "user"
        }
 
    if (population =="none" && method != "direct")
        stop(method, " method only applies to population estimates")
    beta <-  coef(fit)
    nabeta <- is.na(beta)  # undetermined coefficients
    vmat <-  vcov(fit)
    assign <- fit$assign
    term.label <- attr(Terms, "term.labels")
    
    # grab the dispersion
    if (missing(ss)) do.ss <- FALSE
    else do.ss <- ss
    if (class(fit)[1] =="lm") {
        if (missing(ss)) do.ss <- TRUE
        sigma <- summary(fit)$sigma
        }
    else if(class(fit)[1]=="glm") {
        sigma <- summary(fit)$dispersion
#        if (is.null(sigma)) sigma <- 1
        }
    else sigma <- NULL

    ff <- parent.frame()
    tempenv <- new.env(parent=ff)
    assign("cm", function(...) cmatrix(fit, ...), env=tempenv)
    test <- eval(substitute(test), tempenv)

    # check that the test argument is legal.  
    # It can be a single matrix or a list, each element of a list can be
    #  a matrix or list.  All matrices have to be the right size.
    ncoef <- length(beta)
    legal <- function(x, lname="") {
        if (is.matrix(x) && ncol(x)==ncoef) TRUE
        else if (is.list(x)) {
            tname <- names(x)
            tname <- ifelse(tname=="", tname, 1:length(x))
            if (lname!= "") tname <- paste(lname, tname, sep=', ')
            for (i in 1:length(x)) legal(x[[i]], tname[i])
        }
        else stop("invalid test element", lname)
    }       
    legal(test, attr(test, "label"))

    if (population=="none" || method=="nstt") { 
        # no population was given
        tfun <- function(x) {
            if (!is.null(attr(x, "global")) && attr(x, "global")) {
                # Do a global test on all children
                tmat <- do.call(rbind, x)
                c(cfun(tmat, beta, vmat, sigma^2), lapply(x, tfun))
            }
            else if (is.matrix(x)) cfun(x, beta, vmat, sigma^2)
            else lapply(x, tfun)
        }
    } else  if (method=="sgtt") {
        <<yates-sgtt>>
    }
    else {
        # This is essentially the same approach as non-pop, but with
        #  an extra step to fill in the data set
        tfun <- function(x) {
            if (!is.null(attr(x, "global")) && attr(x, "global")) {
                # Do a global test on all children
                tmat <- yatespop(do.call(rbind, x), assign, mf) 
                c(cfun(tmat, beta, vmat, sigma^2), lapply(x, tfun))
            }
            else if (is.matrix(x)) {
                tmat <- yatespop(x, assign, mf)
                cfun(yatespop(x), beta, vmat, sigma^2)
            else lapply(x, tfun)
        }
  }
    }
    class(result) <- "yates"
    attr(result, "label") <- attr(test, "label")
    result #initial testing, just return the result
} 
@

The population routine.  This was hard to create because I got confused.
There are 3 types of terms in the model: those that are part of the
contrast itself, those that interact with the contrast terms, and all
the others.  Group 1 is trivial: leave it alone.
Group 3 is easy: simply replace those coolmns of test with the matching
column mean of the X matrix.  
For group 2, we need to completely rebuild each row of the contrast
of the 
For each row of the X matrix, separately
\begin{enumerate}
  \item 

<<yates-none>>=
tfun <- function(x) {
    if (!is.null(attr(x, "global")) && attr(x, "global")) {
        # Do a global test on all children
        tmat <- do.call(rbind, x)
        c(cfun(tmat, beta, vmat, sigma^2), lapply(x, tfun))
    }
    else cfun(x, beta, vmat, sigma^2)
}
result <- tfun(test)
@ 

For a population estimate the first task is to build the data set.
<<yates-data>>=
@ 

<<yates-pop>>=
@ 

This function is used by the print routine, but it is worthwhile to
expose it.  Some user's might want to print things on their own.

<<yates>>=
as.matrix.yates <- function(x, indent=4) {
    # Create the labels column
    space <- paste(rep(" ", indent), collapse="")
    namefun <- function(zed, indent) {
        if (is.list(zed)){
            sublist <- sapply(zed, is.list)
            if (any(sublist)) {
                i2 <- paste0(space, indent)
                n2 <- names(zed)[sublist]
                temp <- lapply(zed[sublist], namefun, indent=i2)
                for (i in 1:length(temp)) 
                    temp[[i]] <- paste0(i2, c(n2[i], temp[[i]]))
                c(paste0(indent, attr(zed, "label")),
                  unlist(temp, use.names=FALSE))
            }
            else NULL
        }
        else  NULL
    }
    tname <- namefun(x, "")

    # unlist a particular element of the array
    grabit <- function(x, what) {
        sublist <- sapply(x, is.list)
        temp <- if (what %in% names(x) && length(x[[what]])==1) x[[what]] 
                else NA
        if (any(sublist)) c(temp, unlist(lapply(x[sublist], grabit, what=what)))
        else temp
    }
 
    temp <- cbind(grabit(x, "estimate"),
                  sqrt(grabit(x, "var")),
                  grabit(x, "test"),
                  grabit(x, "df"),
                  grabit(x, "ss"))
    dimnames(temp) <- list(tname, c("estimate", "std", "test", "df", "SS"))
    if (all(is.na(temp[,5]))) temp <- temp[, -5]
    temp
}

print.yates <- function(x, ...) 
    print(as.matrix(x), na.print="")
@ 
