\documentclass{report}[11pt]
\usepackage{Sweave}
\usepackage{amsmath}
\addtolength{\textwidth}{1in}
\addtolength{\oddsidemargin}{-.5in}
\setlength{\evensidemargin}{\oddsidemargin}
%\VignetteIndexEntry{The survival package}

\SweaveOpts{keep.source=TRUE, fig=FALSE}
% Ross Ihaka suggestions
\DefineVerbatimEnvironment{Sinput}{Verbatim} {xleftmargin=2em}
\DefineVerbatimEnvironment{Soutput}{Verbatim}{xleftmargin=2em}
\DefineVerbatimEnvironment{Scode}{Verbatim}{xleftmargin=2em}
\fvset{listparameters={\setlength{\topsep}{0pt}}}
\renewenvironment{Schunk}{\vspace{\topsep}}{\vspace{\topsep}}

% I had been putting figures in the figures/ directory, but the standard
%  R build script does not copy it and then R CMD check fails
\SweaveOpts{prefix.string=compete,width=6,height=4}

\newcommand{\myfig}[1]{\includegraphics[height=!, width=\textwidth]
                        {compete-#1.pdf}}

\newcommand{\code}[1]{\texttt{#1}}
\setkeys{Gin}{width=\textwidth}
<<echo=FALSE>>=
options(continue="  ", width=60)
options(SweaveHooks=list(fig=function() par(mar=c(4.1, 4.1, .3, 1.1))))
pdf.options(pointsize=10) #text in graph about the same as regular text
options(contrasts=c("contr.treatment", "contr.poly")) #ensure default
library("survival")
palette(c("#000000", "#D95F02", "#1B9E77", "#7570B3", "#E7298A", "#66A61E"))

# These functions are used in the document, but not discussed until the end
crisk <- function(what, horizontal = TRUE, ...) {
    nstate <- length(what)
    connect <- matrix(0, nstate, nstate,
                      dimnames=list(what, what))
    connect[1,-1] <- 1  # an arrow from state 1 to each of the others
    if (horizontal) statefig(c(1, nstate-1),  connect, ...)
    else statefig(matrix(c(1, nstate-1), ncol=1), connect, ...)
}

state3 <- function(what, horizontal=TRUE, ...) {
    if (length(what) != 3) stop("Should be 3 states")
    connect <- matrix(c(0,0,0, 1,0,0, 1,1,0), 3,3,
                      dimnames=list(what, what))
    if (horizontal) statefig(1:2, connect, ...)
    else statefig(matrix(1:2, ncol=1), connect, ...)
}

state4 <- function() {
    sname <- c("Entry", "CR", "Transplant", "Transplant")
    layout <- cbind(c(1/2, 3/4, 1/4, 3/4),
                    c(5/6, 1/2, 1/2, 1/6))
    connect <- matrix(0,4,4, dimnames=list(sname, sname))
    connect[1, 2:3] <- 1
    connect[2,4] <- 1
    statefig(layout, connect)
}

state5 <- function(what, ...) {
    sname <- c("Entry", "CR", "Tx", "Rel", "Death")
    connect <- matrix(0, 5, 5, dimnames=list(sname, sname))
    connect[1, -1] <- c(1,1,1, 1.4)
    connect[2, 3:5] <- c(1, 1.4, 1)
    connect[3, c(2,4,5)] <- 1
    connect[4, c(3,5)]  <- 1
    statefig(matrix(c(1,3,1)), connect, cex=.8,...)
}
@

\title{The survival package}
\author{Terry Therneau}

\begin{document}
\maketitle

\chapter{Introduction}
\section{History}
Work on the survival package began in 1985 in connection with the analysis
of medical research data, without any realization at the time that the
work would become a package.
Eventually the software was placed on the Statlib repository hosted by
Carnegie Mellon University. 
Multiple version were released in this fashion but I don't have a list of
dates --- version 2 was the first to
make use of the \code{print} method that was introduced in `New S' in 1988,
which places that release somewhere in 1989.
The library was eventually incorportated directly in S-Plus, and from there it
became a standard part of R.

Looking back, I think that 
one of the primary reasons for the package's success is that all of the
functions have been written to solve real analysis questions that arose from
real data sets; theoretical issues were explored when necessary but they 
never played a leading role.  
As a statistician in a major medical center, the central focus of my department
is to advance medicine; statistics is a tool to that end.
This also highlights one of the deficiencies of the package: if a particular
analysis question has not yet arisen in one of my studies then the survival 
package will also have nothing to say on the topic. 
Luckily there are many other R packages that build on or extend
the survival package, and anyone working in the field (the author included) 
should expect to use more packages than just this one.
The author certainly never foresaw that the library would become as popular 
as it has.

This vignette is an introduction to version 3.x of the survival package. 
We can think of versions 1.x as the S-Plus era and 2.1 -- 2.44 as maturation of
the package in R.
Version 3 had 4 major goals.
\begin{itemize} 
  \item Make multi-state curves and models as easy to use as an ordinary
    Kaplan-Meier and Cox model.
  \item Deeper support for absolute risk estimates.
  \item More consitent support of robust variance estimates.
  \item Clean up various naming inconsistencies that have arisen over time.
\end{itemize}

With over 600 dependent packages in 2019, not counting Bioconductor, other
guiding lights of the change are
\begin{itemize}
  \item We can't do everything (so don't try).
  \item Allow other packages to build on this one.  That means clear 
    documentation of all of the objects that are produced, the use of simple
    S3 objects that are easy to manipulate, and setting up many 
    of the routines as a pair.  For example \code{concordance} and 
    \code{concordancefit}; the former is the user front end and the latter does 
    the actual work.  Other package authors might want to access the lower level
    interface, accepting the penalty of fewer error checks. 
  \item Don't bugger it up!
\end{itemize}

This meant preserving the current argument names as much as possible.
Appendix \ref{sect:changes} summarizes changes that were made which are not
backwards compatable.

The two other major changes are to collapse many of vignettes into this single
large one, and the parallel creation of an actual book.  
We've recognized that the package needs more than a vignette.  
With the book's appearance this vignette can also
be more brief, essentially leaving out a lot of the theory.

Version 3 will not appear all at once, however; it will take some time to get 
all of the documentation sorted out in the way that we like.

\section{Survival data}
The survival package is concerned with time-to-event analysis.
Such outcomes arise very often in the analysis of medical data:
time from chemotherapy to tumor recurrence, the durability of a joint
replacement, recurrent lung infections in subjects with cystic fibrosis,
the appearance of hypertension, hyperlipidemia and other comorbidities 
of age, and of course death itself, from which the overall label of
``survival'' analysis derives.  
A key principle of all such studies is that ``it takes time to observe
time'', which in turn leads to two of the primary challenges.
\begin{enumerate}
  \item Incomplete information.  At the time of an analysis, not everyone
    will have yet had the event.  This is a form of partial information
    known as \emph{censoring}: if a particular subject was enrolled in a
    study 2 years ago, and has not yet had an event at the time of
    analysis, we only know that their time to event is $>2$ years.
  \item Dated results.  In order to report 5 year survival, say, from a 
    treatment, patients need to be enrolled and then followed for 5+ years.
    By the time recruitment and follow-up is finished, analysis done, 
    the report finally published the treatment in question might be 8
    years old and considered to be out of date.  This leads to a tension
    between early reporting and long term outcomes.
\end{enumerate}

<<states, fig=TRUE>>=
oldpar <- par(mar=c(.1, .1, .1, .1), mfrow=c(2,2))
sname1 <- c("Alive", "Dead")
cmat1 <- matrix(c(0,0,1,0), nrow=2, 
                dimnames=list(sname1, sname1))
statefig(c(1,1), cmat1)

sname2 <- c("0", "1", "2", "...")
cmat2 <- matrix(0, 4,4, dimnames= list(sname2, sname2))
cmat2[1,2] <- cmat2[2,3] <- cmat2[3,4] <- 1
statefig(c(1,1,1,1), cmat2, bcol=c(1,1,1,0))

sname3 <- c("Entry", "Transplant", "Withdrawal", "Death")
cmat3 <- matrix(0, 4,4, dimnames=list(sname3, sname3))
cmat3[1, -1] <- 1
statefig(c(1,3), cmat3)

sname4 <- c("Health", "Illness", "Death")
cmat4 <- matrix(0, 3, 3, dimnames = list(sname4, sname4))
cmat4[1,2] <- cmat4[2,1] <- cmat4[-3, 3] <- 1
statefig(c(1,2), cmat4, offset=.03)

par(oldpar)
@

Survival data is often represented as
a pair $(t_i, \delta_i)$ where $t$ is the time until endpoint or last
follow-up, and $\delta$ is a 0/1 variable with 0= ``subject was censored at
$t$'' and 1 =``subject had an event at $t$'',
or in R code as \code{Surv(time, status)}.  
The status variable can be logical, e.g., \code{vtype=='death'} where 
\code{vtype} is the variable ``visit type''.  
An alternate view is to think of time to event data as a multi-state process
as is shown in the above figure. 
The upper left panel is simple survival with two states of alive and dead,
``classic'' survival analysis.
The other three panels show repeated events of the same type (upper right)
competing risks for subjects on a liver transplant waiting list(lower left) 
and the illness-death model (lower right).
In this approach interest normally centers on the transition rates or hazards
(arrows) from state to state (box to box).
For simple survival the two viewpoints are equivalent, and we will move
freely between them, i.e., use whichever viewpoint is handy at the moment,
either ``time to event'' or ``rate of events''.  
When there more than one transition the rate approach is particularly useful.

The figure also displays a 2 by 2 division of survival data sets:
one event type (top row) versus multiple types of events 
(bottom row), and  one endpoint per subject (left column) versus multiple
events per subject (right column).  

\chapter{Survival and cumulative hazard curves}
\section{Simple curves}
\index{function!survfit}%
\index{survival curves!one event}
The most common simple depiction of survival is the Kaplan-Meier curve,
which is created with the \code{survfit} function.
The left-hand side of the formula will be a Surv object and the right hand
side contains one or more categorical variables that will divide the 
observations into groups.  For a single curve use \code{\textascitilde 1}
as the right hand side.

<<survfit1>>=
fit1 <- survfit(Surv(time, status) ~ sex, data=lung)
print(fit1, rmean= 913)

summary(fit1, times= (0:4)*182.5)
@ 

The default printout is very brief, only one line per curve, showing the
number of observations, number of events, median survival, and
optionally the restricted mean survival time (RMST) in each of
the groups.  In the above case we used the value at 2.5 years = 913 days
as the upper threshold for the RMST, the value of 453 for females 
in an expected survival for 453 or the next 913 days after enrollment
in the study.
The summary function gives a more complete description of the curve,
in this case we chose to show the values every 6 months for the first two years.

Arguments for the survfit function include the usual
\code{data}, \code{weights}, \code{subset} and \code{na.action} 
arguments common to modeling formulas.
A further set of arguments have to do with standard errors and confidence
intervals, defaults are shown in parenthesis.
\begin{itemize}
  \item se.fit (TRUE): compute a standard error of the estimates.  
    In a few rare circumstances omitting the standard error  can save 
    computation time.
  \item conf.int (.95): the level of confidence interval, or FALSE if
    intervals are not desired.
  \item conf.type ('log'): transformation to be used in computing the
    confidence intervals. 
  \item conf.lower ('ususal'): optional modification of the lower interval.
\end{itemize}

\index{survfit!confidence intervals}
For the default \code{conf.type} the confidence intervals are computed as
$$
   e^{\log(p) \pm 1.96 {\rm se}(\log(p))}
$$
rather than the direct formula of $p \pm 1.96 {\rm(se)}(p)$, where 
$p = S(t)$ is the survival probability.
Many authors have investigated the behavior of transformed intervals, and a 
general conclusion is that the direct intervals do not behave well, particularly
near 0 and 1, while all the others are acceptable. 
Which of the choices of log, log-log, or logit is ``best'' depends on the 
details of the simulation study.
(The default corresponds to the most recent paper the author had read, at
the time the default was chosen; a current meta review might give a slight edge
to log-log option.)

The \code{conf.lower} option is mostly used for graphs.  If a study has a 
long string of censored observations, it is intuitive that the precision
of the estimated survival must be decreasing due to a smaller sample size,
but the formal standard error will not change until the next death.
This option widens the confidence interval between death times, proportional
to the number at risk, giving a visual clue of the decrease in $n$.
There is a small (and decreasing) population of users who like the option,
most users will ignore it.

\index{function!plot.survfit}
The most common use of survival curves is to plot them, as shown below.
<<survfit2, fig=TRUE>>=
plot(fit1, col=2:1, xscale=365.25, lwd=2, conf.times=c(.5, 1, 1.5, 2)*365,  
     xlab="Years since study entry", ylab="Survival")
legend(730, .8, c("Female", "Male"), col=1:2, lwd=2, bty='n')
@ 

Curves will appear in the plot in the same order as they are listed by 
\code{print}, which in turn gives reveals the association of each subject
with the color or linetype used for each. 
Curves can also be labeled using the \code{pch} option to place marks on 
the curves.
The location of the marks is controlled by the \code{mark.time} option
which has a default value of FALSE (no marks).  A vector of numeric values
specifies the location of the marks, optionally a value of TRUE will cause a 
mark to appear at each censoring time; this can result in far too many marks
if $n$ is large, however.
By default confidence intervals are included on the plot of there is a single
curve, and omitted if there is more than one curve.  

The result of a \code{survfit} call can be subscripted.  This is useful
when one wants to plot only a subset of the curves.
\index{survfit!subscript}
<<survfit3>>=
fit2 <- survfit(Surv(time, status) ~  sex + ph.ecog, data=lung)
fit2
plot(fit2[1:3], lty=1:3, lwd=2, xscale=365.25,
       xlab="Years after enrollment", ylab="Survival")
legend(550, .8, paste("Peformance Score", 0:2, sep=' ='), 
       lty=1:3, lwd=2, bty='n')
text(400, .95, "Males", cex=2)
@ 

\section{Repeated events}
\index{survival curves!repeated events}
Repeated events of the same type is quite common in industrial reliability
data.
As an example consider a data set on the replacement times of
diesel engine valve seats.
The simple data set \code{valveSeats} contains an engine identifier, time, and
a status of 1 for a replacement and 0 for the end of the inspection interval
for that engine; sorted by time within engine.
To accomodate multiple events per subject each row needs to span a unique
time interval $(t1, t2]$, we do this by adding a new variable to the data
set.
Intervals of 0 are illegal for \code{Surv} objects, so we move one event back
in time by a small amount, for the few engines that had 2 repairs on the
same day. 

<<survival4>>=
vdata <- valveSeat
first <- !duplicated(vdata$id)
vdata$t0 <- ifelse(first, 0,  c(0, vdata$time[-nrow(vdata)]))
double <- which(vdata$t0 == vdata$time)
vdata$time[double-1] <- vdata$t0[double] <- vdata$t0[double] -.1
vdata[1:7, c("id", "t0", "time", "status")]
multicheck(Surv(t0, time, status) ~ 1, id=id, data=vdata)
@ 

Creation of (start time, end time) intervals is a common data manipulation 
tasks when there are multiple events per subject. 
A later chapter will discuss the \code{tmerge} function, which is very often
useful for this task. 
The \emph{multicheck} function can be used as check for some of more common
errors that arise in creation, 
it aslo will be covered in more detail in a later section.
(The output will be also be less cryptic for later cases, where the states 
have been labeled.) 
In the above data the engines could only participate in 2 kinds of transitions:
from an unnamed initial state to a repair, () $\rightarrow 1, or from one
repair to another one, 1 $\rightarrow$ 1, or reach end of follow-up.
The second table printed by \code{multicheck} tells us the 17 engines had 0
transitions to state 1, i.e., no valve repairs before the end of observation
for that engine, 9 had 1 repair, etc.
Perhaps the most important output is that the routine did not print any 
warnings about suspicious data.

We can now compute the survival estimate.  When there are multiple observations
per subject the \code{id} statement is necessary.
(It is a good idea if there \emph{could} be multiples, even if there are none,
as it lets the underlying routines check for doubles.)

<<survival5, fig=TRUE>>=
vfit <- survfit(Surv(t0, time, status) ~1, data=vdata, id=id)
plot(vfit, cumhaz=TRUE, xlab="Days", ylab="Cumulative hazard")
@ 

By default, the \code{survfit} routine computes both the survival and
the cumulative hazard functions,
to plot the cumulative hazard portion the \code{cumhaz} argument of
\code{survfit} is used.
\index{cumulative hazard function}%
\index{mean cumulative function|see cumulative hazard function}  
In multi-event data, the cumulative hazard is an estimate of the expected
\emph{number} of events for a unit that has been observed for the 
given amount of time, whereas the survival $S$ estimates the probability that
a unit has had 0 repairs.
The cumulative hazard is often the more natural quantity to plot in such 
studies; in reliability analysis it is also known as the 
\emph{mean cumulative function}.  
The estimate is also important in multi-state models.

\section{Multi-state models}
In the classic case \code{status} is either a logical or 0/1 numeric variable
that represents censoring (0 or false) or an event (1 or true),
and the result is a survival curve for each group.
If \code{status} is a factor, however, the result is a multi-state
estimate.
In this case the first level of \code{status} is used to code censoring while
the remaining ones are possible states.
Here is a simple competing risks example where the three endpoints are
labeled as a, b and c.
<<simple1>>=
crdata <- data.frame(time= c(1:8, 6:8),
                     endpoint=factor(c(1,1,2,0,1,1,3,0,2,3,0),
                                     labels=c("censor", "a", "b", "c")),
                     cstate=rep("Entry", 11),
                     id= LETTERS[1:11])
tfit  <- survfit(Surv(time, endpoint) ~ 1, data=crdata, id=id, istate=cstate)
dim(tfit)
summary(tfit)
@
The resulting object \code{tfit} contains an estimate of $P$(state),
the probability of being in each state.
$P$ is a matrix with one row for each time and one column for
each of the four states a--c and the "no event as of yet" state; we will often
refer to the latter as the entry state.
By definition each row of $P$ sums to 1.
The plot of the fit will have 3 curves, by default the curve for an
unnamed state is not displayed.
(Since they sum to 1 one of the 4 curves is redundant, and the entry state
is normally the least interesting of the set.)
<<fig=TRUE>>=
plot(tfit, col=1:4, lwd=2, ylab="Probability in state")
@ 

The resulting \code{survfms} object appears as a matrix and can be
subscripted as such, with a column for each state and rows for each
group that was created by any variables on the right hand side of the formula.
This makes it simple to display a subset of the curves using plot
or lines commands.
The unnamed state in the above fit, for instance, can be displayed with
\code{plot(tfit[,4])}.

The curves are computed using the Aalen-Johansen estimator.  
The Kaplan-Meier estimate and the 
cumulative incidence estimate (for competing risks) are each a special case of
the AJ estimate. 
The AJ is more general, however; a given subject can have multiple 
transitions from state to state, including transitions to a state that was 
visited earlier. 
In this case the dataset structure is similar to that for time varying
covariates in a Cox model: the time variable will be intervals $(t_1, t_2]$
which are open on the left and closed on the right, the status variable
contains the state that was entered at time $t_2$, and a subject will have
multiple lines of data.
There are a few restrictions.
\begin{itemize} 
  \item An identifier variable is required which indicates which rows of the
    data frame belong to each subject.  If the \code{id} argument is missing
    the code assumes that each row of data is a separate subject, which leads
    to a nonsense estimate when there are actually multiple rows for each. 
  \item Subjects do not have to enter at time 0 or all at the same time,
    but each must traverse a connected segment of time.  Disjoint intervals
    such as the pair $(0,5]$, $(8, 10]$ are illegal.
   \item A subject cannot change groups.  Any covariates on the right hand
     side of the formula must remain constant within subject.  (This 
     function is not
     a way to creat supposed `time-dependent' survival curves.)
   \item Subjects may have case weights, and these weights may change over
     time for a subject.
\end{itemize}

By default every subject is assumed to start in an unnamed common entry state.
The \code{istate} argument can instead be used to designate an entry state 
for each subject; like variables in the formula it is searched for in the
\code{data} argument.
The distribution of states at the first event time is 
treated as the initial distribution of states;
in common with ordinary survival any observation which is censored before the 
first event time has no impact on the results.

The extended example below is intended to give more information about the
routines.

\section{Data set}
The \code{myeloid} data set contains simulated data which mimics
that from a trial in subjects with  acute myeloid
leukemia.
In this comparison of two conditioning regimens the
canonical path for a subject is initial therapy $\rightarrow$
complete response (CR) $\rightarrow$
hematologic stem cell transplant (HSCT) $\rightarrow$
sustained remission, followed by relapse or death.

<<overall>>=
myeloid[1:5,]
@ 
The first few rows of data are shown above.
The data set contains the follow-up time and status at last follow-up 
for each subject, along with the time to transplant
(txtime),
complete response (crtime) or relapse after CR (rltime).
Subject 1 did not receive a transplant, as shown by the NA value,
and subject 2 did not achieve CR.

\begin{figure}
  \myfig{sfit0}
  \caption{Overall survival curves for the two treatments.}
  \label{sfit0}
\end{figure}

Overall survival curves for the data are shown in figure \ref{sfit0}.
The difference between the treatment arms A and B
is substantial.  A goal of this analysis is to better 
understand this difference.  Here is the code to generate the 
simple survival curves:

<<sfit0, echo=TRUE, fig=TRUE, include=FALSE>>=
sfit0 <- survfit(Surv(futime, death) ~ trt, myeloid)
plot(sfit0, xscale=365.25, xaxs='r', col=1:2, lwd=2,
     xlab="Years post enrollment", ylab="Survival")
legend(20, .4, c("Arm A", "Arm B"),
       col=1:2, lwd=2, bty='n')
@ 














As an simple multi-state example consider the monoclonal gammopathy data
 set \code{mgus2},
which contains the time to a plasma cell malignancy (PCM), usually
multiple myleoma,  and the 
time to death for 1384 subjects found to have a condition known as
monoclonal gammopathy of undetermined significance (MGUS), based on
a particular test.  
The time values in the data set are from detection of the condition.
Here are a subset of the observations:

<<survfit-mgus1, fig=TRUE>>=
mgus2[56:59,]

sname <- c("MGUS", "Malignancy", "Death")
smat <- matrix(c(0,0,0, 1,0,0, 1,1,0), 3, 3, 
               dimnames = list(sname, sname))
statefig(c(1,2), smat)
@ 

The \code{statefig} function can be used to draw a simple ``box and arrow''
diagram for the multistate model.
In this data set 
subject 56 was diagnosed with a PCM 29 months after detection of MGUS and
died at 44 months. 
This subject passes through all three states.
The other three listed individuals died without a plasma cell malignancy
and traverse one of the arrows;
103 subjects (not shown) are censored before experiencing either event
and spend their entire tenure in the leftmost state.

The \code{statefig} function is designed to create simple state diagrams,
with an emphasis on ease rather than elegance. 
\index{function!statefig}
The authors find such diagrams invaluable when working though an analysis
and want to encourage users to draw them, hence a focus on simplicity. 
The basic arguments were the vector 1:2, which stats that the drawing should
put one state in the first column and the next two in a second column,
and a matrix of connections \code{smat},
\code{smat[i,j] =1} if there are transitions from state $i$ to state $j$
and 0 otherwise.  The dimnames of the matrix are used for the box labels.
Calls can be a little bit more complex, but not much: there are options to
set colors for the text, boxes, and lines, line widths, and line types.
The first argument to the function can instead be a two column matrix 
containing the horizontal and vertical coordinates for the center of each
box, for those who desire finer control.
The routine returns a two column matrix containing the coordinates of the
center of each box, which could be used to guide further annotation
if desired. 
 
To compute the multi-state survival, we first create a data set with
(begin, end) time intervals using \code{tmerge}.
As is often the case, a closer look at the data uncovered some special
issues: there are 9 subjects whose time to progression is identical to
the death time.
It turns out that these are subjects whose disease was discovered at
autopsy.
The survival code does not allow for time intervals of length zero (one
cannot spend 0 days in the malignancy state), so an exception needs to
be made.  Clearly, these autopsied subjects will have had their 
malignancy for some period of time before death, below we arbitrarily
move the PCM date 1 month back.

<<survfit-mgus2>>=
# modified progression time, = -1 month if tied with death
temp <- with(mgus2, ifelse(pstat==0, NA,
                           ifelse(ptime==futime, ptime-1, ptime)))
mdata <- tmerge(mgus2[,1:7], mgus2, id=id, event= event(futime, 2*death),
                event= event(temp))
mdata$event <- factor(mdata$event, 0:2, c("censor", "PCM", "Death"))
mdata[56:59,]
multicheck(Surv(tstart, tstop, event) ~ 1, mdata, id=id)
@ 
 
The short dataset printout shows that subject 56 is represented as two rows,
the first from entry to PCM, with a length of 29 months, and second 
spanning from 29 to 44 months and ending with death.
The transition table from the \code{multicheck} output shows transitions
from the entry state ``()'' to PCM and Death, and from PCM to Death.
\index{function!multicheck}
Importantly, it does not show any transitions from PCM to PCM, which by
the study definition can only occur once, or from Death to some other state.
The table of per subject counts shows 103 subjects who make 2 transitions,
but no one who has multiple PCM or death events.
We are now ready to compute an estimate.

The \code{survfit} function computes and Aalen-Johansen estimate of
the probability in state vector $p(t)$.
The resulting vector has 3 elements in this case,
$p_1(t) = $Pr(in the Entry state at time $t$), 
$p_2(t) = $Pr(in the Malignancy state at time $t$) and
$p_3(t) = $Pr(in the death state at time $t$).
The result is saved as an $m$ by 3 matrix, where $m$ is the number of unique
event and censoring times.

The Aalen-Johansen estimate is a simple matrix product
\begin{align*}
  p(t) = p(0) \prod_{s \le t} T(s)  \label {aj1}\\
  T(s) = \left( \begin{array}{ccc}
      \box & \lambda_{12}(s) & \lambda_{13}(s) \\
      \lambda_{21}(s) & \box & \lambda_{23}(s)  \\
      \lambda_{31}(s) & \lambda_{32}(s) & \box \end{array} \right) 
  \label{aj2}
\end{align}
The transition rates $\lambda_{jk}(s)$ in the matrix are simply the fraction of 
subjects who were observed to make a transtion from state $j$ to state $k$ at
time $s$, among all those who were at risk for such a transition,
i.e. all those in state $j$ just before time $s$.
There is a matrix for each time an event occurs, and
each row of the matrix is constrained to sum to 1: everyone has to go somewhere
(or stay home). 
We left the diagonal blank in \eqref{aj2} since it can be filled in last. 
It is a fairly simple exercise to verify that the Aalen-Johansen estimate
reduces to the Kaplan-Meier estimate for the two state alive-dead model,
or more technically that $p_1(t) = S(t)$ = probability of being in the alive
state at time $t$ and $p_2(t) = 1-S(t)$ = probability of being in the dead
state at time $t$.
One can also verify that for competing risks data it gives the same estimate
as the well known (but horribly named) \emph{cumulative incidence}
estimator.    

For the 3 state MGUS model $\lambda_{32}=0$ and $\lambda_{31}=0$: there are no
transtions from death; $\lambda_{21}=0$ as well.
Since the data set does not contain a ``current state'' variable, only the
transitions, everyone is assumed to start in a common unnamed state ``()''
with $p(0) = (1,0,0)$ to reflect this.
Here is a fit and plot of the competing risks subset of our figure, i.e.,
ignoring the transitions from malignancy to death.

<<survfit-mgus3>>=
mfit <- survfit(Surv(tstart, tstop, event) ~ sex, id = id,
                data=mdata, subset= (tstart==0))
mfit
plot(mfit, col=1:2, lty=c(1,1,2,2), lwd=2, xlim=c(0,400),
     xlab="Months from MGUS diagnosis", ylab= "P(state)")
legend(10, .85, c("Male, death w/o PCM", "Female, death w/o PCM"), lty=2, 
       lwd=2, col=2:1, bty='n')
legend(200, .3, c("Female, PCM", "Male, PCM"), lty=1, lwd=2,
       col=1:2, bty='n')
@  

The default printout now included the restricted mean (RMST) rather
than a median.  
The reason is that for a general multi-state model the $p(t)$ = probability
in state curves can both rise and fall, so the median of a curve is not
well defined.   The RMST however corresponds to the mean time spent in the
state, and has a direct interpretation in all cases, even when subjects
might enter and leave the state multiple times.


\section{Two state models}
\section{Competing risks}
\section{General models}

\chapter{The proportional hazard (Cox) model}

\chapter{Multi-event proportional hazards models}
\section{Single event type}
\section{Competing risks}
A simple example of competing risks is the MGUS data set, a state
space diagrem for the model is shown below with plasma cell malignancy (PCM)
and death as the endpoints.
The \code{mgus2} data set has separate variables for time to progression
and time to death.  
Nine subjects had progression detected at autopsy, for those we move the
progression time 1 month earlier to avoid ties.

<<mstate>>=
states <- c("MGUS", "PCM", "Death")
tmat <- matrix(c(0,0,0, 1,0,0, 1,0,0), 3,3, 
               dimnames=list(states, states))
statefig(1:2, tmat)

# modified progression time, = -1 month if tied with death
temp <- with(mgus2, ifelse(pstat==0, NA,
                           ifelse(ptime==futime, ptime-1, ptime)))
mdata <- tmerge(mgus2[,1:7], mgus2, id=id, event= event(futime, 2*death),
                event= event(temp))
mdata <- tmerge(mdata, mdata, id=id, enum = cumtdc(tstart)) # add row num
mdata$event <- factor(mdata$event, 0:2, c("censor", "PCM", "Death"))
@ 

The competing risks data consists of only the first event for each subject,
so we subset the data when fitting the model.

<<cfit1>>=
cfit <- coxph(Surv(tstart, tstop, event) ~ I(age/10) + sex + mspike, 
              id = id, mdata, subset=(tstart==0))
print(cfit, digits=1)  # narrow the printout a bit
dummy <- expand.grid(age=c(60, 80), sex=c("M","F"), mspike=1)
csurv <- survfit(cfit, newdata=dummy)
#csurv <- survfit(cfit, newdata=expand.grid(age=60, sex="F", mspike=1))

@ 
The effect of age and sex on non-PCM mortality is profound, which is not
a surprise given the median starting age of \Sexpr{median(mgus2$age)}. %$
Death rates rise \Sexpr{round(exp(10*coef(cfit)[4]),1)} fold per decade 
of age and
the death rate for males is \Sexpr{round(exp(coef(cfit)[5]),1)} times as great
as that for females.  
The size of the serum monoclonal spike has almost no impact on non-PCM 
mortality.
A 1 unit increase changes mortality by only 2\%.

The mspike size has a major impact on progression, however; each 1 gram
change increases risk by \Sexpr{round(exp(coef(cfit)[3]) ,1)} fold.
The interquartile range of \code{mspike} is 0.9 grams so this risk increase
is clinically important.
The effect of age on the progression rate is much less pronounced,
with a coefficient only 1/4 that for mortality, while the effect of sex
on progression is completely negligible.

The effect of sex on the \emph{lifetime} probability of PCM is not zero,
however.  Because of a longer lifetime, a female with MGUS will on average
spend more total years at risk for malignancy than the average male, and so 
will accumulate a larger lifetime risk of PCM.  
The average rate of progression is about 1\% per year, as shown below,
while the mean post diagnosis lifetime is 19 months longer for 
females. 
The overall effect is a 1.6\% increase in lifetime risk.
<<mpyears>>=
pfit1 <- pyears(Surv(ptime, pstat) ~ sex, mgus2, scale=12)
round(100* pfit1$event/pfit1$pyears, 1)  # PCM rate per year

sfit1 <- survfit(Surv(tstop, event) ~ sex, mdata)
temp <- summary(sfit1, rmean="common")  #print the mean survival time
round(temp$table[1:2,3], 1)
@ 

\appendix
\chapter{Changes from version 2.44 to 3.0}
Not all of these may be completed by 3.0, but this is the roadmap.

\section{Changes in version 3}
Version 3.0 of the package was released in conjunction with a book.  Writing
the book, and in particular the examples, revealed some shortcomings in 
the design.
In particular, there were some common concepts which had appeared piecemeal in
more than one function, but not using the same keywords.  Two particular areas
are survival curves and multiple observations per subject.

Survival and cumulative hazard curves are genereated by the 
\code{survfit} function, either from
raw data (survfit.formula), or a fitted Cox or parametric survival model
(survfit.coxph, survfit.survreg). 
Two choices that appear are
\begin{enumerate}
  \item If there are tied event times, to estimate the hazard using a 
    straightforward increment of (number of events)/(number at risk), or
    make a correction for the ties.  The simpler method is known variously
    as the Nelson, Aalen, Breslow, and Tsiatis estimate, along with hypenenated
    forms combining 2 or 3 of them.
    One of the simpler corrections for ties is known as the Fleming-Harrington
    approximation when used with raw data, and the Efron when used 
    in a Cox model.
  \item The survival curve $S(t)$ can be estimated directly or as the
    exponential of the cumulative hazard estimate.  The first of these is
    known as the Kaplan-Meier, cumulative incidence (CI), Aalen-Johansen,
    and Kalbfleisch-Prentice estimate, depending on context, 
    the second as a Fleming-Harringtion, Breslow, or Efron estimate, again
    depending on context.
\end{enumerate}

With respect to the two above, subtypes of the \code{survfit} routine have
had either a \code{type} or \code{method} argument over the years which tried
to capture both of these at the same time, 
and consequently have had a bewildering number of options,
for example ``fleming-harrington'' in \code{survfit.formula} 
stood for the simple cumulative hazard
estimate plus the exponential survival estimate, 
``fh2'' specified the tie-corrected cumulative hazard plus exponential survival,
while \code{survfit.coxph} used ``breslow'' and ``efron'' for the same two
combinations.
The updated routines now have separate \code{stype} and \code{ctype}
arguments.  For the first 1= direct and 2=exponent of the cumulative hazard
and for the second 1=simple and 2= corrected for ties. 

The Cox model is a special case in two ways: 
1. the the way in which ties are treated
in the likelihood should match the way they are treated in creating the hazard
and 2. the direct estimate of survival can be very difficult to compute.
The survival package's default is to use the \code{ctype} option 
which matches the ties option
of the \code{coxph} call along with an exponential estimate of survival.
This \code{ctype} choice preserves some useful properties of the martingale
residuals.

A second issue is multiple observations per subject, and how those impact
the computations.  This leads to 3 common arguments of
\begin{itemize}
  \item id: an identifier in each row of the data, which allows the routines
    to identify multiple rows for a subject
  \item cluster: identify correlated rows, which should be combined when
    creating the robust variance
  \item robust: TRUE or FALSE, to compute a robust variance.
\end{itemize}

These arguments have been inconsistent in the past, partly because of the
sequential appearance of multiple use cases.  The package started with
only the simplest data form: one observation per subject, one endpoint.
To this has been added
\begingroup
\renewcommand{\theenumi}{\alph{enumi}}
\begin{enumerate}
  \item Multiple observations per subject
  \item Multiple endpoints per subject
  \item Multiple types of endpoints
\end{enumerate}
\endgroup

Case (a) arises as a way to code time-dependent covariates, and in this
case an \code{id} statement is not needed, and in fact you will get the
same estimates and standard errors with or without it. 
(There will be a change in the counts of subjects who leave or enter an
interval, since an observation pair (0, 10), (10, 20) for the same subject
will not count as an exit (censor) at 10 along with an entry at 10.)
If (b) is true then the robust variance is called for, one will want to 
have either a \code{cluster} argument or the \code{robust=TRUE} argument.
In the coxph routine a \code{cluster(group)} term in the model statement
can be used instead of the cluster argument,
but this is no longer the preferred form. 
When (b) and (c) are true then the \code{id} statement is required in order
to obtain a correct \emph{estimate} of the result. 
This is also the case for (c) alone when subjects do not all start in the
same state.  
For competing risks data --- multiple endpoints, 
everyone starts in the same state, only one transition per subject --- 
the \code{id} statement is not necessary nor (I think) is a robust variance.

When there is an \code{id} statement but no \code{cluster} or \code{robust}
directive, then the programs will use (b) as a litmus test to decide
between model based or robust variance, if possible.
(There are edge cases where only one of the two variance estimates has 
been implemented, however).
If there is a \code{cluster} argument then \code{robust=TRUE} is assumed.
If only a \code{robust=TRUE} argument is given
then the code treats each line of data as independent.

\section{Survfit}
  The survfit object is changing.   The primary change has to do with the 
starting time.  When the package was first written in the late 1980s I made
the decision to \emph{not} include the initial point of the survival curve
(time=0, S=1) as a part of the \code{time} and \code{survival} parts of the
object; they could get tacked on by the plot function.
With the addition of delayed start (\code{start.time} option) and then
more importantly multi-state models, the starting point is not always a
simple (0,1) pair, which led to the addition of new components to the
objects to hold the additional information, and increasing if-then-else logic
in the downstream routines that process the curves.  In v3 the first point
is now bundled in as part of the time, surv, pstate, std.err, and etc 
components. 

Two functions survfit23 and survfit32 convert
between the version 2 \code{survfit} object  and new \code{survfit3} forms.  
This has allowed us make any changes incrementally.

Other changes are    
\begin{itemize}
  \item Common arguments of id, cluster, and influence
  \item The routines now produce both the estimated survival and the
    estimated cumulative hazard, along with their errors 
  \item Some code paths produced std(S) and some std(log(S)), the object now
    contains a \code{log.se} flag telling which.  (Before, downstream routines
    just ``had to know'').
  \item an explicit ``v3'' flag in the object
\end{itemize}

\section{Coxph}
 The multi-state objects include a \code{states} vector, which is a simple
list of the state names.
The \code{cmap} component is an integer matrix  with one row for each term in the
model and one column for each transition. 
Each element indexes a position in the coefficient vector and variance matrix.
\begin{itemize}
  \item Column labels are of the form 1:2, which denotes a transition from
    \code{state[1]} to \code{state[2]}.
  \item If a particluar term in the data, ``age'' say, was not part of the model
    for a particular transition then a 0 will appear in that position 
    of \code{cmap}.
  \item If two transitions share a common coefficient, both those element of
    \code{cmap} will point to the same location.
  \item The first row of \code{cmap}, labeled ``stratum'', is numbered separately
    and partitions the transtions into disjoint strata.
\end{itemize}

\end{document}


